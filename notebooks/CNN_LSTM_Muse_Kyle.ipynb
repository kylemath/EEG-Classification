{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_LSTM_2_Kyle.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylemath/EEG-Classification/blob/master/notebooks/CNN_LSTM_Muse_Kyle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cH7KRd8ZZPMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN_LSTM_Kyle\n",
        "\n",
        "Goal is to make a CNN LSTM stack that processes EEG trials as input and predicts binary category as output.\n",
        "\n",
        "\n",
        "Strategy:\n",
        "* Current code uses 25,000 examples of 100 long sentences in two categories, \n",
        "* Then is tested on 25000 sequences as well\n",
        "* Instead try 250 by 100 data point long ERP for each trial \n",
        "* Predict target vs standard on any EEG dataset (start with Nathan skateboard data)\n",
        "* Predict attend left vs attend right on muse 375 data\n",
        "\n",
        "Using: \n",
        "* https://github.com/keras-team/keras/blob/master/examples/imdb_cnn_lstm.py\n",
        "* https://github.com/pbashivan/EEGLearn\n",
        "* https://github.com/tevisgehr/EEG-Classification\n",
        "\n",
        "Resources:\n",
        "*   http://proceedings.mlr.press/v56/Thodoroff16.pdf\n",
        "*   https://arxiv.org/abs/1511.06448\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VXe-o8XtG9ki",
        "colab_type": "code",
        "outputId": "7b0662ad-7ac9-4a43-9468-d2e5abe01e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tevisgehr/EEG-Classification.git\n",
        "!git clone https://github.com/kylemath/eeg-notebooks.git\n",
        "#%cd EEG-Classification\n",
        "!ls\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'EEG-Classification' already exists and is not an empty directory.\n",
            "Cloning into 'eeg-notebooks'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 1632 (delta 62), reused 145 (delta 43), pack-reused 1466\u001b[K\n",
            "Receiving objects: 100% (1632/1632), 107.78 MiB | 20.28 MiB/s, done.\n",
            "Resolving deltas: 100% (685/685), done.\n",
            "Checking out files: 100% (485/485), done.\n",
            "EEG-Classification  eeg-notebooks  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_NcbDGsG6_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from eeg_learn_functions import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSvKReofG6_I",
        "colab_type": "code",
        "outputId": "9e7e029b-e89a-4842-9448-74c255216e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as scs\n",
        "import re\n",
        "from numpy import genfromtxt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.precision = 4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gSGBQBcXG6_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Brainwave Frequencies:\n",
        "Gamma, 30 to 50 Hz.  \n",
        "Beta, 14 to 30 Hz.  \n",
        "Alpha, 8 to 14 Hz.  \n",
        "Theta, 4 to 8 Hz.  \n",
        "Delta, 0.1 to 4 Hz.  "
      ]
    },
    {
      "metadata": {
        "id": "w8_YWq7dG6_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Bin Size: \n",
        "https://stackoverflow.com/questions/25735153/plotting-a-fast-fourier-transform-in-python  \n",
        "(Search for 'bin')"
      ]
    },
    {
      "metadata": {
        "id": "j5mm0SyFG6_T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "An EEG processing library:  \n",
        "https://github.com/pbashivan/EEGLearn"
      ]
    },
    {
      "metadata": {
        "id": "8buBuEsbG6_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "theta = (4,8)\n",
        "alpha = (8,12)\n",
        "beta = (12,40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "asaiRYdZG6_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_fft(snippet):\n",
        "    Fs = 128.0;  # sampling rate\n",
        "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
        "    snippet_time = len(snippet)/Fs\n",
        "    Ts = 1.0/Fs; # sampling interval\n",
        "    t = np.arange(0,snippet_time,Ts) # time vector\n",
        "\n",
        "    # ff = 5;   # frequency of the signal\n",
        "    # y = np.sin(2*np.pi*ff*t)\n",
        "    y = snippet\n",
        "#     print('Ts: ',Ts)\n",
        "#     print(t)\n",
        "#     print(y.shape)\n",
        "    n = len(y) # length of the signal\n",
        "    k = np.arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[range(n//2)] # one side frequency range\n",
        "\n",
        "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
        "    Y = Y[range(n//2)]\n",
        "    #Added in: (To remove bias.)\n",
        "    #Y[0] = 0\n",
        "    return frq,abs(Y)\n",
        "#f,Y = get_fft(np.hanning(len(snippet))*snippet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uNwMQSrQG6_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def theta_alpha_beta_averages(f,Y):\n",
        "    theta_range = (4,8)\n",
        "    alpha_range = (8,12)\n",
        "    beta_range = (12,40)\n",
        "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
        "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
        "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
        "    return theta, alpha, beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbOLRN1ZG6_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_steps(samples,frame_duration,overlap):\n",
        "    '''\n",
        "    in:\n",
        "    samples - number of samples in the session\n",
        "    frame_duration - frame duration in seconds \n",
        "    overlap - float fraction of frame to overlap in range (0,1)\n",
        "    \n",
        "    out: list of tuple ranges\n",
        "    '''\n",
        "    #steps = np.arange(0,len(df),frame_length)\n",
        "    Fs = 128\n",
        "    i = 0\n",
        "    intervals = []\n",
        "    samples_per_frame = Fs * frame_duration\n",
        "    while i+samples_per_frame <= samples:\n",
        "        intervals.append((i,i+samples_per_frame))\n",
        "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
        "    return intervals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "beuByNJWG6_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_frames(df,frame_duration):\n",
        "    '''\n",
        "    in: dataframe or array with all channels, frame duration in seconds\n",
        "    out: array of theta, alpha, beta averages for each probe for each time step\n",
        "        shape: (n-frames,m-probes,k-brainwave bands)\n",
        "    '''\n",
        "    Fs = 128.0\n",
        "    frame_length = Fs*frame_duration\n",
        "    frames = []\n",
        "    steps = make_steps(len(df),frame_duration,overlap)\n",
        "    for i,_ in enumerate(steps):\n",
        "        frame = []\n",
        "        if i == 0:\n",
        "            continue\n",
        "        else:\n",
        "            for channel in df.columns:\n",
        "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
        "                f,Y =  get_fft(snippet)\n",
        "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
        "                frame.append([theta, alpha, beta])\n",
        "            \n",
        "        frames.append(frame)\n",
        "    return np.array(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjRzRkWCG6_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "locs_2d = [(-2.0,4.0),\n",
        "           (2.0,4.0),\n",
        "           (-1.0,3.0),\n",
        "           (1.0,3.0),\n",
        "           (-3.0,3.0),\n",
        "           (3.0,3.0),\n",
        "           (-2.0,2.0),\n",
        "           (2.0,2.0),\n",
        "           (-2.0,-2.0),\n",
        "           (2.0,-2.0),\n",
        "           (-4.0,1.0),\n",
        "           (4.0,1.0),\n",
        "           (-1.0,-3.0),\n",
        "           (1.0,-3.0)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oI7oDkqdG6_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
        "    '''\n",
        "    IN: \n",
        "    file_names - list of strings for each input file (one for each subject)\n",
        "    labels - list of labels for each\n",
        "    image_size - int size of output images in form (x, x)\n",
        "    frame_duration - time length of each frame (seconds)\n",
        "    overlap - float fraction of frame to overlap in range (0,1)\n",
        "    \n",
        "    OUT:\n",
        "    X: np array of frames (unshuffled)\n",
        "    y: np array of label for each frame (1 or 0)\n",
        "    '''\n",
        "    ##################################\n",
        "    ###Still need to do the overlap###!!!\n",
        "    ##################################\n",
        "    \n",
        "    Fs = 128.0   #sampling rate\n",
        "    frame_length = Fs * frame_duration\n",
        "    \n",
        "    print('Generating training data...')\n",
        "    \n",
        "    \n",
        "    for i, file in enumerate(file_names):\n",
        "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
        "        data = genfromtxt(file, delimiter=',').T\n",
        "        df = pd.DataFrame(data)\n",
        "        \n",
        "        X_0 = make_frames(df,frame_duration)\n",
        "        #steps = np.arange(0,len(df),frame_length)\n",
        "        X_1 = X_0.reshape(len(X_0),14*3)\n",
        "        \n",
        "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
        "        images = np.swapaxes(images, 1, 3) \n",
        "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
        "        print('\\n')\n",
        "        if i == 0:\n",
        "            X = images\n",
        "            y = np.ones(len(images))*labels[0]\n",
        "        else:\n",
        "            X = np.concatenate((X,images),axis = 0)\n",
        "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
        "        \n",
        "        \n",
        "    return X,np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "uhinfgcdG6_z",
        "colab_type": "code",
        "outputId": "8537e23b-2c02-4c43-a159-33545bf1a21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "file_names = ['data/ML101_KS.csv',\n",
        "              'data/ML101_US.csv',\n",
        "              'data/ML102_KS.csv',\n",
        "              'data/ML102_US.csv',\n",
        "              'data/ML103_KS.csv',\n",
        "              'data/ML103_US.csv',\n",
        "              'data/ML104_KS.csv',\n",
        "              'data/ML104_US.csv',\n",
        "              'data/ML105_KS.csv',\n",
        "              'data/ML105_US.csv',\n",
        "              'data/ML106_KS.csv',\n",
        "              'data/ML106_US.csv',\n",
        "              'data/ML107_KS.csv',\n",
        "              'data/ML107_US.csv',\n",
        "              'data/ML108_KS.csv',\n",
        "              'data/ML108_US.csv']\n",
        "\n",
        "#file_names = ['data/ML102_KS.csv',\n",
        "#              'data/ML102_US.csv']\n",
        "\n",
        "\n",
        "labels = [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
        "image_size = 28\n",
        "frame_duration = 1.0\n",
        "overlap = 0.5\n",
        "X, y = make_data_pipeline(file_names,labels,image_size,frame_duration,overlap)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating training data...\n",
            "Processing session:  data/ML101_KS.csv . ( 1  of  16 )\n",
            "234  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML101_US.csv . ( 2  of  16 )\n",
            "224  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML102_KS.csv . ( 3  of  16 )\n",
            "222  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML102_US.csv . ( 4  of  16 )\n",
            "218  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML103_KS.csv . ( 5  of  16 )\n",
            "226  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML103_US.csv . ( 6  of  16 )\n",
            "208  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML104_KS.csv . ( 7  of  16 )\n",
            "202  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML104_US.csv . ( 8  of  16 )\n",
            "204  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML105_KS.csv . ( 9  of  16 )\n",
            "214  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML105_US.csv . ( 10  of  16 )\n",
            "226  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML106_KS.csv . ( 11  of  16 )\n",
            "230  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML106_US.csv . ( 12  of  16 )\n",
            "278  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML107_KS.csv . ( 13  of  16 )\n",
            "246  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML107_US.csv . ( 14  of  16 )\n",
            "236  frames generated with label  0 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML108_KS.csv . ( 15  of  16 )\n",
            "240  frames generated with label  1 .\n",
            "\n",
            "\n",
            "Processing session:  data/ML108_US.csv . ( 16  of  16 )\n",
            "234  frames generated with label  0 .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bAr90EeaG6_2",
        "colab_type": "code",
        "outputId": "3578d1ac-8b6b-495f-80c9-3e228a25c1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3642, 28, 28, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "jP90d308G6_7",
        "colab_type": "code",
        "outputId": "c5303ccd-9f09-4446-cb14-a62a3bd84773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y.shape\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3642,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "7j-lctn_G7AA",
        "colab_type": "code",
        "outputId": "1c92d0c3-81f3-47a3-c700-554e72aab865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X[10]);\n",
        "plt.colorbar()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fc00a78e6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAD8CAYAAADAKumpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQlPiUpEwlOiEpHwlKhEJDwlKhEJ7/8BZKNahmxn+PwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u5FhwRdqG7AF",
        "colab_type": "code",
        "outputId": "92d6f3d1-cf6c-4ea5-8426-190ff35015c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "cell_type": "code",
      "source": [
        "# Two subplots, the axes array is 1-d\n",
        "f, axarr = plt.subplots(2,2, figsize = (8,8))\n",
        "axarr[0][0].set_title('Known Skill')\n",
        "axarr[0][0].imshow(X[0])\n",
        "axarr[1][0].imshow(X[1])\n",
        "\n",
        "axarr[0][1].set_title('Unknown Skill')\n",
        "axarr[0][1].imshow(X[20])\n",
        "axarr[1][1].imshow(X[21])\n",
        "\n",
        ";"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAHjCAYAAABvpmXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "U1-kvK4gG7AL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train_temp, y_test_temp = train_test_split(X, y, test_size=0.20,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zgSrs-0jG7AO",
        "colab_type": "code",
        "outputId": "9afdb449-5961-4574-b81b-f59b9b208a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_train_temp.shape)\n",
        "print(x_train.shape)\n",
        "print(y_test_temp.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2913,)\n",
            "(2913, 28, 28, 3)\n",
            "(729,)\n",
            "(729, 28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2MRkAL-0Yl93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1535fb43-30eb-4283-81b3-72abddb449c8"
      },
      "cell_type": "code",
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "#x_train /= 255\n",
        "#x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "input_shape = (img_rows, img_cols, 3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (2913, 28, 28, 3)\n",
            "2913 train samples\n",
            "729 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "JxjbgyC5G7AZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import LSTM, ConvLSTM2D\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 2\n",
        "epochs = 400\n",
        "lstm_output_size = 10\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train_temp, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test_temp, num_classes)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(ConvLSTM2D(lstm_output_size,input_shape=input_shape,kernel_size=3))\n",
        "#model.add(Dense(num_classes))\n",
        "#model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xyz97yRsG7Ad",
        "colab_type": "code",
        "outputId": "385a8b7a-331a-4d84-9cfc-c5f94e14d49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34034
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True,\n",
        "          verbose=True)\n",
        "                   "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2913 samples, validate on 729 samples\n",
            "Epoch 1/1000\n",
            "2913/2913 [==============================] - 4s 2ms/step - loss: 0.7059 - acc: 0.5084 - val_loss: 0.6937 - val_acc: 0.4746\n",
            "Epoch 2/1000\n",
            "2913/2913 [==============================] - 0s 98us/step - loss: 0.6861 - acc: 0.5132 - val_loss: 0.6930 - val_acc: 0.4993\n",
            "Epoch 3/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.6855 - acc: 0.5252 - val_loss: 0.6895 - val_acc: 0.4842\n",
            "Epoch 4/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6802 - acc: 0.5245 - val_loss: 0.6847 - val_acc: 0.5103\n",
            "Epoch 5/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6794 - acc: 0.5403 - val_loss: 0.7047 - val_acc: 0.4966\n",
            "Epoch 6/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.6773 - acc: 0.5544 - val_loss: 0.7109 - val_acc: 0.4925\n",
            "Epoch 7/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.6755 - acc: 0.5479 - val_loss: 0.6837 - val_acc: 0.5528\n",
            "Epoch 8/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.6731 - acc: 0.5503 - val_loss: 0.6760 - val_acc: 0.5775\n",
            "Epoch 9/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6662 - acc: 0.5668 - val_loss: 0.6860 - val_acc: 0.4966\n",
            "Epoch 10/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6717 - acc: 0.5640 - val_loss: 0.6764 - val_acc: 0.5624\n",
            "Epoch 11/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6649 - acc: 0.5736 - val_loss: 0.6876 - val_acc: 0.4883\n",
            "Epoch 12/1000\n",
            "2913/2913 [==============================] - 0s 79us/step - loss: 0.6629 - acc: 0.5719 - val_loss: 0.6676 - val_acc: 0.5981\n",
            "Epoch 13/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6590 - acc: 0.5891 - val_loss: 0.6635 - val_acc: 0.5953\n",
            "Epoch 14/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6571 - acc: 0.5802 - val_loss: 0.6689 - val_acc: 0.5391\n",
            "Epoch 15/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.6531 - acc: 0.5925 - val_loss: 0.6653 - val_acc: 0.5871\n",
            "Epoch 16/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6551 - acc: 0.5884 - val_loss: 0.6612 - val_acc: 0.5871\n",
            "Epoch 17/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6532 - acc: 0.6001 - val_loss: 0.6569 - val_acc: 0.6228\n",
            "Epoch 18/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.6497 - acc: 0.5905 - val_loss: 0.6725 - val_acc: 0.5075\n",
            "Epoch 19/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6431 - acc: 0.6159 - val_loss: 0.6530 - val_acc: 0.6104\n",
            "Epoch 20/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6473 - acc: 0.6011 - val_loss: 0.6616 - val_acc: 0.5789\n",
            "Epoch 21/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.6406 - acc: 0.6224 - val_loss: 0.6624 - val_acc: 0.5350\n",
            "Epoch 22/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6466 - acc: 0.6062 - val_loss: 0.6544 - val_acc: 0.5940\n",
            "Epoch 23/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6395 - acc: 0.6052 - val_loss: 0.6465 - val_acc: 0.6063\n",
            "Epoch 24/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6401 - acc: 0.6083 - val_loss: 0.6524 - val_acc: 0.6077\n",
            "Epoch 25/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6355 - acc: 0.6248 - val_loss: 0.7081 - val_acc: 0.4883\n",
            "Epoch 26/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6419 - acc: 0.6155 - val_loss: 0.6447 - val_acc: 0.6049\n",
            "Epoch 27/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6318 - acc: 0.6217 - val_loss: 0.6679 - val_acc: 0.5309\n",
            "Epoch 28/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6398 - acc: 0.6179 - val_loss: 0.6492 - val_acc: 0.6008\n",
            "Epoch 29/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6283 - acc: 0.6299 - val_loss: 0.7092 - val_acc: 0.5254\n",
            "Epoch 30/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6335 - acc: 0.6196 - val_loss: 0.6420 - val_acc: 0.6337\n",
            "Epoch 31/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6263 - acc: 0.6371 - val_loss: 0.6437 - val_acc: 0.6104\n",
            "Epoch 32/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.6268 - acc: 0.6299 - val_loss: 0.7033 - val_acc: 0.5350\n",
            "Epoch 33/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.6317 - acc: 0.6251 - val_loss: 0.6405 - val_acc: 0.6159\n",
            "Epoch 34/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.6252 - acc: 0.6344 - val_loss: 0.6475 - val_acc: 0.6173\n",
            "Epoch 35/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.6223 - acc: 0.6385 - val_loss: 0.6345 - val_acc: 0.6132\n",
            "Epoch 36/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6214 - acc: 0.6461 - val_loss: 0.6412 - val_acc: 0.6036\n",
            "Epoch 37/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6225 - acc: 0.6313 - val_loss: 0.6386 - val_acc: 0.6091\n",
            "Epoch 38/1000\n",
            "2913/2913 [==============================] - 0s 79us/step - loss: 0.6198 - acc: 0.6450 - val_loss: 0.6339 - val_acc: 0.6406\n",
            "Epoch 39/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6160 - acc: 0.6419 - val_loss: 0.7198 - val_acc: 0.5679\n",
            "Epoch 40/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6301 - acc: 0.6334 - val_loss: 0.6390 - val_acc: 0.6008\n",
            "Epoch 41/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6132 - acc: 0.6519 - val_loss: 0.6650 - val_acc: 0.5967\n",
            "Epoch 42/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6137 - acc: 0.6505 - val_loss: 0.6269 - val_acc: 0.6296\n",
            "Epoch 43/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6124 - acc: 0.6564 - val_loss: 0.6298 - val_acc: 0.6118\n",
            "Epoch 44/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6221 - acc: 0.6337 - val_loss: 0.6277 - val_acc: 0.6461\n",
            "Epoch 45/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.6095 - acc: 0.6529 - val_loss: 0.6239 - val_acc: 0.6420\n",
            "Epoch 46/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6146 - acc: 0.6450 - val_loss: 0.6271 - val_acc: 0.6310\n",
            "Epoch 47/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6066 - acc: 0.6553 - val_loss: 0.6228 - val_acc: 0.6187\n",
            "Epoch 48/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6091 - acc: 0.6567 - val_loss: 0.6264 - val_acc: 0.6241\n",
            "Epoch 49/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6111 - acc: 0.6536 - val_loss: 0.6377 - val_acc: 0.6091\n",
            "Epoch 50/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6148 - acc: 0.6478 - val_loss: 0.6258 - val_acc: 0.6063\n",
            "Epoch 51/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.6046 - acc: 0.6529 - val_loss: 0.6185 - val_acc: 0.6392\n",
            "Epoch 52/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6059 - acc: 0.6498 - val_loss: 0.6356 - val_acc: 0.6159\n",
            "Epoch 53/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6049 - acc: 0.6471 - val_loss: 0.6298 - val_acc: 0.6296\n",
            "Epoch 54/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.6031 - acc: 0.6498 - val_loss: 0.6195 - val_acc: 0.6241\n",
            "Epoch 55/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6007 - acc: 0.6560 - val_loss: 0.6123 - val_acc: 0.6420\n",
            "Epoch 56/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.6029 - acc: 0.6560 - val_loss: 0.6212 - val_acc: 0.6228\n",
            "Epoch 57/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5956 - acc: 0.6670 - val_loss: 0.6138 - val_acc: 0.6228\n",
            "Epoch 58/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6058 - acc: 0.6516 - val_loss: 0.6475 - val_acc: 0.5995\n",
            "Epoch 59/1000\n",
            "2913/2913 [==============================] - 0s 79us/step - loss: 0.6006 - acc: 0.6660 - val_loss: 0.6532 - val_acc: 0.6091\n",
            "Epoch 60/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.6022 - acc: 0.6560 - val_loss: 0.6119 - val_acc: 0.6461\n",
            "Epoch 61/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5937 - acc: 0.6677 - val_loss: 0.6287 - val_acc: 0.6063\n",
            "Epoch 62/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.6068 - acc: 0.6601 - val_loss: 0.6355 - val_acc: 0.6077\n",
            "Epoch 63/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5961 - acc: 0.6694 - val_loss: 0.6205 - val_acc: 0.6365\n",
            "Epoch 64/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5938 - acc: 0.6625 - val_loss: 0.6305 - val_acc: 0.6036\n",
            "Epoch 65/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5995 - acc: 0.6680 - val_loss: 0.6136 - val_acc: 0.6200\n",
            "Epoch 66/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5887 - acc: 0.6722 - val_loss: 0.6059 - val_acc: 0.6461\n",
            "Epoch 67/1000\n",
            "2913/2913 [==============================] - 0s 79us/step - loss: 0.5911 - acc: 0.6732 - val_loss: 0.6066 - val_acc: 0.6475\n",
            "Epoch 68/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5949 - acc: 0.6718 - val_loss: 0.6023 - val_acc: 0.6461\n",
            "Epoch 69/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5906 - acc: 0.6698 - val_loss: 0.6161 - val_acc: 0.6324\n",
            "Epoch 70/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5870 - acc: 0.6691 - val_loss: 0.6477 - val_acc: 0.5981\n",
            "Epoch 71/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5926 - acc: 0.6694 - val_loss: 0.6102 - val_acc: 0.6337\n",
            "Epoch 72/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5891 - acc: 0.6759 - val_loss: 0.6008 - val_acc: 0.6447\n",
            "Epoch 73/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5886 - acc: 0.6742 - val_loss: 0.6245 - val_acc: 0.6324\n",
            "Epoch 74/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5868 - acc: 0.6842 - val_loss: 0.6033 - val_acc: 0.6461\n",
            "Epoch 75/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5940 - acc: 0.6739 - val_loss: 0.6000 - val_acc: 0.6543\n",
            "Epoch 76/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5854 - acc: 0.6828 - val_loss: 0.6176 - val_acc: 0.6228\n",
            "Epoch 77/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5833 - acc: 0.6770 - val_loss: 0.5986 - val_acc: 0.6475\n",
            "Epoch 78/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5784 - acc: 0.6866 - val_loss: 0.5979 - val_acc: 0.6543\n",
            "Epoch 79/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5847 - acc: 0.6845 - val_loss: 0.6122 - val_acc: 0.6337\n",
            "Epoch 80/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5840 - acc: 0.6855 - val_loss: 0.5945 - val_acc: 0.6516\n",
            "Epoch 81/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5829 - acc: 0.6835 - val_loss: 0.6063 - val_acc: 0.6529\n",
            "Epoch 82/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5803 - acc: 0.6859 - val_loss: 0.6247 - val_acc: 0.6173\n",
            "Epoch 83/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5816 - acc: 0.6794 - val_loss: 0.6173 - val_acc: 0.6104\n",
            "Epoch 84/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5841 - acc: 0.6739 - val_loss: 0.6022 - val_acc: 0.6571\n",
            "Epoch 85/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5788 - acc: 0.6855 - val_loss: 0.5955 - val_acc: 0.6584\n",
            "Epoch 86/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5885 - acc: 0.6845 - val_loss: 0.6055 - val_acc: 0.6529\n",
            "Epoch 87/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5715 - acc: 0.7003 - val_loss: 0.6092 - val_acc: 0.6639\n",
            "Epoch 88/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5716 - acc: 0.7003 - val_loss: 0.5995 - val_acc: 0.6626\n",
            "Epoch 89/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5803 - acc: 0.6945 - val_loss: 0.6008 - val_acc: 0.6584\n",
            "Epoch 90/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5830 - acc: 0.6763 - val_loss: 0.5983 - val_acc: 0.6406\n",
            "Epoch 91/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5728 - acc: 0.6900 - val_loss: 0.6109 - val_acc: 0.6255\n",
            "Epoch 92/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5784 - acc: 0.6893 - val_loss: 0.6177 - val_acc: 0.6132\n",
            "Epoch 93/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5709 - acc: 0.6928 - val_loss: 0.5891 - val_acc: 0.6571\n",
            "Epoch 94/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5739 - acc: 0.6890 - val_loss: 0.5895 - val_acc: 0.6584\n",
            "Epoch 95/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5762 - acc: 0.6852 - val_loss: 0.6252 - val_acc: 0.6475\n",
            "Epoch 96/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5750 - acc: 0.6938 - val_loss: 0.6084 - val_acc: 0.6337\n",
            "Epoch 97/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5684 - acc: 0.6952 - val_loss: 0.6029 - val_acc: 0.6379\n",
            "Epoch 98/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5690 - acc: 0.6941 - val_loss: 0.6231 - val_acc: 0.6475\n",
            "Epoch 99/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5725 - acc: 0.6766 - val_loss: 0.6018 - val_acc: 0.6694\n",
            "Epoch 100/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5671 - acc: 0.7003 - val_loss: 0.5849 - val_acc: 0.6557\n",
            "Epoch 101/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5699 - acc: 0.6852 - val_loss: 0.6539 - val_acc: 0.6132\n",
            "Epoch 102/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5693 - acc: 0.6955 - val_loss: 0.6135 - val_acc: 0.6255\n",
            "Epoch 103/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5658 - acc: 0.6948 - val_loss: 0.6052 - val_acc: 0.6694\n",
            "Epoch 104/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5717 - acc: 0.6945 - val_loss: 0.6785 - val_acc: 0.6091\n",
            "Epoch 105/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5677 - acc: 0.7051 - val_loss: 0.5903 - val_acc: 0.6626\n",
            "Epoch 106/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5627 - acc: 0.7058 - val_loss: 0.5870 - val_acc: 0.6831\n",
            "Epoch 107/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5701 - acc: 0.7041 - val_loss: 0.5871 - val_acc: 0.6626\n",
            "Epoch 108/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5614 - acc: 0.6958 - val_loss: 0.5998 - val_acc: 0.6379\n",
            "Epoch 109/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5647 - acc: 0.7075 - val_loss: 0.6116 - val_acc: 0.6557\n",
            "Epoch 110/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5754 - acc: 0.6952 - val_loss: 0.5826 - val_acc: 0.6790\n",
            "Epoch 111/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5598 - acc: 0.7075 - val_loss: 0.6053 - val_acc: 0.6639\n",
            "Epoch 112/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5615 - acc: 0.7048 - val_loss: 0.6228 - val_acc: 0.6214\n",
            "Epoch 113/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5629 - acc: 0.7061 - val_loss: 0.5813 - val_acc: 0.6680\n",
            "Epoch 114/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5646 - acc: 0.7024 - val_loss: 0.5791 - val_acc: 0.6667\n",
            "Epoch 115/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5619 - acc: 0.7068 - val_loss: 0.5806 - val_acc: 0.6639\n",
            "Epoch 116/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5616 - acc: 0.7034 - val_loss: 0.6052 - val_acc: 0.6310\n",
            "Epoch 117/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5594 - acc: 0.7065 - val_loss: 0.6004 - val_acc: 0.6502\n",
            "Epoch 118/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5578 - acc: 0.7096 - val_loss: 0.6306 - val_acc: 0.6324\n",
            "Epoch 119/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5597 - acc: 0.7161 - val_loss: 0.6066 - val_acc: 0.6626\n",
            "Epoch 120/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5587 - acc: 0.7037 - val_loss: 0.6050 - val_acc: 0.6337\n",
            "Epoch 121/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5564 - acc: 0.7058 - val_loss: 0.5821 - val_acc: 0.6763\n",
            "Epoch 122/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5594 - acc: 0.7103 - val_loss: 0.5877 - val_acc: 0.6584\n",
            "Epoch 123/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5666 - acc: 0.7041 - val_loss: 0.5768 - val_acc: 0.6708\n",
            "Epoch 124/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5514 - acc: 0.7188 - val_loss: 0.5822 - val_acc: 0.6667\n",
            "Epoch 125/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5643 - acc: 0.7034 - val_loss: 0.6072 - val_acc: 0.6584\n",
            "Epoch 126/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5520 - acc: 0.7182 - val_loss: 0.5762 - val_acc: 0.6859\n",
            "Epoch 127/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5555 - acc: 0.7151 - val_loss: 0.5743 - val_acc: 0.6749\n",
            "Epoch 128/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5496 - acc: 0.7151 - val_loss: 0.6212 - val_acc: 0.6502\n",
            "Epoch 129/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5573 - acc: 0.7072 - val_loss: 0.5791 - val_acc: 0.6708\n",
            "Epoch 130/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5495 - acc: 0.7171 - val_loss: 0.6078 - val_acc: 0.6529\n",
            "Epoch 131/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5555 - acc: 0.7041 - val_loss: 0.5821 - val_acc: 0.6735\n",
            "Epoch 132/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5585 - acc: 0.7027 - val_loss: 0.5699 - val_acc: 0.6653\n",
            "Epoch 133/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5466 - acc: 0.7243 - val_loss: 0.5910 - val_acc: 0.6447\n",
            "Epoch 134/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5593 - acc: 0.7020 - val_loss: 0.5822 - val_acc: 0.6626\n",
            "Epoch 135/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5477 - acc: 0.7147 - val_loss: 0.6420 - val_acc: 0.6584\n",
            "Epoch 136/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5522 - acc: 0.7103 - val_loss: 0.5840 - val_acc: 0.6722\n",
            "Epoch 137/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5535 - acc: 0.7106 - val_loss: 0.5740 - val_acc: 0.6776\n",
            "Epoch 138/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5481 - acc: 0.7240 - val_loss: 0.5720 - val_acc: 0.6818\n",
            "Epoch 139/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5515 - acc: 0.7147 - val_loss: 0.5714 - val_acc: 0.6831\n",
            "Epoch 140/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5489 - acc: 0.7110 - val_loss: 0.5882 - val_acc: 0.6886\n",
            "Epoch 141/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5450 - acc: 0.7233 - val_loss: 0.5792 - val_acc: 0.6708\n",
            "Epoch 142/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5481 - acc: 0.7140 - val_loss: 0.5687 - val_acc: 0.6818\n",
            "Epoch 143/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5453 - acc: 0.7110 - val_loss: 0.6746 - val_acc: 0.5981\n",
            "Epoch 144/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5543 - acc: 0.7134 - val_loss: 0.5664 - val_acc: 0.6790\n",
            "Epoch 145/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5415 - acc: 0.7247 - val_loss: 0.5824 - val_acc: 0.6845\n",
            "Epoch 146/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5505 - acc: 0.7130 - val_loss: 0.5722 - val_acc: 0.6859\n",
            "Epoch 147/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5584 - acc: 0.7120 - val_loss: 0.5676 - val_acc: 0.6872\n",
            "Epoch 148/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5394 - acc: 0.7257 - val_loss: 0.5680 - val_acc: 0.6859\n",
            "Epoch 149/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5457 - acc: 0.7130 - val_loss: 0.5734 - val_acc: 0.6859\n",
            "Epoch 150/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5362 - acc: 0.7271 - val_loss: 0.5936 - val_acc: 0.6502\n",
            "Epoch 151/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5484 - acc: 0.7250 - val_loss: 0.5844 - val_acc: 0.6818\n",
            "Epoch 152/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5441 - acc: 0.7168 - val_loss: 0.5690 - val_acc: 0.6818\n",
            "Epoch 153/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5430 - acc: 0.7195 - val_loss: 0.5782 - val_acc: 0.6639\n",
            "Epoch 154/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5455 - acc: 0.7185 - val_loss: 0.5935 - val_acc: 0.6529\n",
            "Epoch 155/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5352 - acc: 0.7267 - val_loss: 0.6027 - val_acc: 0.6804\n",
            "Epoch 156/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5441 - acc: 0.7243 - val_loss: 0.5985 - val_acc: 0.6392\n",
            "Epoch 157/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5370 - acc: 0.7243 - val_loss: 0.6457 - val_acc: 0.6132\n",
            "Epoch 158/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5395 - acc: 0.7195 - val_loss: 0.5686 - val_acc: 0.6914\n",
            "Epoch 159/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5495 - acc: 0.7233 - val_loss: 0.5753 - val_acc: 0.6886\n",
            "Epoch 160/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5313 - acc: 0.7439 - val_loss: 0.5835 - val_acc: 0.6818\n",
            "Epoch 161/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5425 - acc: 0.7137 - val_loss: 0.5645 - val_acc: 0.6955\n",
            "Epoch 162/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5305 - acc: 0.7326 - val_loss: 0.5870 - val_acc: 0.6488\n",
            "Epoch 163/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5424 - acc: 0.7110 - val_loss: 0.5649 - val_acc: 0.6955\n",
            "Epoch 164/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5387 - acc: 0.7202 - val_loss: 0.5712 - val_acc: 0.6996\n",
            "Epoch 165/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5355 - acc: 0.7326 - val_loss: 0.5633 - val_acc: 0.6927\n",
            "Epoch 166/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5375 - acc: 0.7305 - val_loss: 0.5604 - val_acc: 0.6968\n",
            "Epoch 167/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5397 - acc: 0.7233 - val_loss: 0.5607 - val_acc: 0.6886\n",
            "Epoch 168/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5365 - acc: 0.7298 - val_loss: 0.5837 - val_acc: 0.6667\n",
            "Epoch 169/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5309 - acc: 0.7291 - val_loss: 0.5752 - val_acc: 0.6955\n",
            "Epoch 170/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5358 - acc: 0.7250 - val_loss: 0.5907 - val_acc: 0.6543\n",
            "Epoch 171/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5415 - acc: 0.7312 - val_loss: 0.5594 - val_acc: 0.6955\n",
            "Epoch 172/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5283 - acc: 0.7350 - val_loss: 0.5737 - val_acc: 0.6749\n",
            "Epoch 173/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5366 - acc: 0.7199 - val_loss: 0.5647 - val_acc: 0.6886\n",
            "Epoch 174/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5293 - acc: 0.7340 - val_loss: 0.6070 - val_acc: 0.6406\n",
            "Epoch 175/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5311 - acc: 0.7243 - val_loss: 0.5586 - val_acc: 0.7023\n",
            "Epoch 176/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5350 - acc: 0.7295 - val_loss: 0.5574 - val_acc: 0.6968\n",
            "Epoch 177/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5323 - acc: 0.7353 - val_loss: 0.6235 - val_acc: 0.6379\n",
            "Epoch 178/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5274 - acc: 0.7336 - val_loss: 0.5587 - val_acc: 0.7010\n",
            "Epoch 179/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5299 - acc: 0.7281 - val_loss: 0.5803 - val_acc: 0.6694\n",
            "Epoch 180/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5333 - acc: 0.7291 - val_loss: 0.5736 - val_acc: 0.6968\n",
            "Epoch 181/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5269 - acc: 0.7329 - val_loss: 0.5851 - val_acc: 0.6886\n",
            "Epoch 182/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5376 - acc: 0.7254 - val_loss: 0.5596 - val_acc: 0.6955\n",
            "Epoch 183/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5220 - acc: 0.7322 - val_loss: 0.5646 - val_acc: 0.6914\n",
            "Epoch 184/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5378 - acc: 0.7202 - val_loss: 0.5571 - val_acc: 0.7023\n",
            "Epoch 185/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5180 - acc: 0.7388 - val_loss: 0.6096 - val_acc: 0.6488\n",
            "Epoch 186/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5300 - acc: 0.7257 - val_loss: 0.5685 - val_acc: 0.6996\n",
            "Epoch 187/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5195 - acc: 0.7357 - val_loss: 0.5617 - val_acc: 0.6955\n",
            "Epoch 188/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5314 - acc: 0.7281 - val_loss: 0.5784 - val_acc: 0.6831\n",
            "Epoch 189/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5250 - acc: 0.7432 - val_loss: 0.5823 - val_acc: 0.6749\n",
            "Epoch 190/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5327 - acc: 0.7233 - val_loss: 0.6259 - val_acc: 0.6749\n",
            "Epoch 191/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5231 - acc: 0.7319 - val_loss: 0.5531 - val_acc: 0.7064\n",
            "Epoch 192/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5179 - acc: 0.7370 - val_loss: 0.5587 - val_acc: 0.6900\n",
            "Epoch 193/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5267 - acc: 0.7288 - val_loss: 0.5745 - val_acc: 0.6749\n",
            "Epoch 194/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5342 - acc: 0.7206 - val_loss: 0.5635 - val_acc: 0.6900\n",
            "Epoch 195/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5196 - acc: 0.7312 - val_loss: 0.6433 - val_acc: 0.6420\n",
            "Epoch 196/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5270 - acc: 0.7367 - val_loss: 0.5642 - val_acc: 0.6886\n",
            "Epoch 197/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5208 - acc: 0.7350 - val_loss: 0.5672 - val_acc: 0.6859\n",
            "Epoch 198/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5212 - acc: 0.7377 - val_loss: 0.5750 - val_acc: 0.6571\n",
            "Epoch 199/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5164 - acc: 0.7360 - val_loss: 0.6205 - val_acc: 0.6598\n",
            "Epoch 200/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5257 - acc: 0.7291 - val_loss: 0.5876 - val_acc: 0.6859\n",
            "Epoch 201/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5272 - acc: 0.7278 - val_loss: 0.5501 - val_acc: 0.7023\n",
            "Epoch 202/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5158 - acc: 0.7312 - val_loss: 0.5579 - val_acc: 0.6982\n",
            "Epoch 203/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5257 - acc: 0.7394 - val_loss: 0.5551 - val_acc: 0.7010\n",
            "Epoch 204/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5147 - acc: 0.7377 - val_loss: 0.6602 - val_acc: 0.6475\n",
            "Epoch 205/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5217 - acc: 0.7305 - val_loss: 0.5750 - val_acc: 0.6694\n",
            "Epoch 206/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5171 - acc: 0.7350 - val_loss: 0.5489 - val_acc: 0.7078\n",
            "Epoch 207/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5233 - acc: 0.7278 - val_loss: 0.5660 - val_acc: 0.6831\n",
            "Epoch 208/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5140 - acc: 0.7412 - val_loss: 0.5717 - val_acc: 0.6941\n",
            "Epoch 209/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.5237 - acc: 0.7343 - val_loss: 0.5663 - val_acc: 0.6859\n",
            "Epoch 210/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5215 - acc: 0.7333 - val_loss: 0.5586 - val_acc: 0.6859\n",
            "Epoch 211/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5142 - acc: 0.7370 - val_loss: 0.5573 - val_acc: 0.6982\n",
            "Epoch 212/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5161 - acc: 0.7436 - val_loss: 0.5498 - val_acc: 0.6982\n",
            "Epoch 213/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5202 - acc: 0.7398 - val_loss: 0.5698 - val_acc: 0.6708\n",
            "Epoch 214/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5158 - acc: 0.7408 - val_loss: 0.5514 - val_acc: 0.7037\n",
            "Epoch 215/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5110 - acc: 0.7370 - val_loss: 0.5892 - val_acc: 0.6735\n",
            "Epoch 216/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.5274 - acc: 0.7326 - val_loss: 0.5500 - val_acc: 0.7119\n",
            "Epoch 217/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5143 - acc: 0.7388 - val_loss: 0.5485 - val_acc: 0.6955\n",
            "Epoch 218/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5107 - acc: 0.7436 - val_loss: 0.5582 - val_acc: 0.6845\n",
            "Epoch 219/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5203 - acc: 0.7336 - val_loss: 0.5721 - val_acc: 0.6927\n",
            "Epoch 220/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5075 - acc: 0.7473 - val_loss: 0.5467 - val_acc: 0.7147\n",
            "Epoch 221/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5135 - acc: 0.7415 - val_loss: 0.5541 - val_acc: 0.7051\n",
            "Epoch 222/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.5112 - acc: 0.7405 - val_loss: 0.5734 - val_acc: 0.6968\n",
            "Epoch 223/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5103 - acc: 0.7432 - val_loss: 0.5565 - val_acc: 0.7037\n",
            "Epoch 224/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5096 - acc: 0.7436 - val_loss: 0.5692 - val_acc: 0.6845\n",
            "Epoch 225/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5249 - acc: 0.7364 - val_loss: 0.5501 - val_acc: 0.7064\n",
            "Epoch 226/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5023 - acc: 0.7559 - val_loss: 0.5789 - val_acc: 0.6845\n",
            "Epoch 227/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5200 - acc: 0.7315 - val_loss: 0.5572 - val_acc: 0.7133\n",
            "Epoch 228/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5019 - acc: 0.7487 - val_loss: 0.5472 - val_acc: 0.7092\n",
            "Epoch 229/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5136 - acc: 0.7487 - val_loss: 0.5592 - val_acc: 0.6982\n",
            "Epoch 230/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5052 - acc: 0.7504 - val_loss: 0.5557 - val_acc: 0.6955\n",
            "Epoch 231/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5104 - acc: 0.7439 - val_loss: 0.5641 - val_acc: 0.6831\n",
            "Epoch 232/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5090 - acc: 0.7473 - val_loss: 0.5769 - val_acc: 0.6722\n",
            "Epoch 233/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5067 - acc: 0.7425 - val_loss: 0.5868 - val_acc: 0.6914\n",
            "Epoch 234/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5139 - acc: 0.7446 - val_loss: 0.5458 - val_acc: 0.7119\n",
            "Epoch 235/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5044 - acc: 0.7501 - val_loss: 0.5647 - val_acc: 0.7010\n",
            "Epoch 236/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5198 - acc: 0.7442 - val_loss: 0.5528 - val_acc: 0.7119\n",
            "Epoch 237/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5011 - acc: 0.7515 - val_loss: 0.5449 - val_acc: 0.7037\n",
            "Epoch 238/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5121 - acc: 0.7418 - val_loss: 0.5430 - val_acc: 0.7174\n",
            "Epoch 239/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.5008 - acc: 0.7545 - val_loss: 0.5494 - val_acc: 0.7023\n",
            "Epoch 240/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5098 - acc: 0.7384 - val_loss: 0.5471 - val_acc: 0.7160\n",
            "Epoch 241/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4995 - acc: 0.7412 - val_loss: 0.5445 - val_acc: 0.7119\n",
            "Epoch 242/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.5008 - acc: 0.7545 - val_loss: 0.6588 - val_acc: 0.6941\n",
            "Epoch 243/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5076 - acc: 0.7501 - val_loss: 0.6085 - val_acc: 0.6859\n",
            "Epoch 244/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5110 - acc: 0.7446 - val_loss: 0.5840 - val_acc: 0.6680\n",
            "Epoch 245/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4988 - acc: 0.7497 - val_loss: 0.5691 - val_acc: 0.6749\n",
            "Epoch 246/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5071 - acc: 0.7473 - val_loss: 0.5645 - val_acc: 0.7064\n",
            "Epoch 247/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.5024 - acc: 0.7552 - val_loss: 0.5401 - val_acc: 0.7160\n",
            "Epoch 248/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.5085 - acc: 0.7422 - val_loss: 0.5587 - val_acc: 0.6955\n",
            "Epoch 249/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4996 - acc: 0.7515 - val_loss: 0.5694 - val_acc: 0.6845\n",
            "Epoch 250/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4983 - acc: 0.7467 - val_loss: 0.5467 - val_acc: 0.7133\n",
            "Epoch 251/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5031 - acc: 0.7456 - val_loss: 0.5533 - val_acc: 0.6982\n",
            "Epoch 252/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5023 - acc: 0.7425 - val_loss: 0.5442 - val_acc: 0.7160\n",
            "Epoch 253/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5028 - acc: 0.7432 - val_loss: 0.5442 - val_acc: 0.7119\n",
            "Epoch 254/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5002 - acc: 0.7556 - val_loss: 0.5448 - val_acc: 0.7064\n",
            "Epoch 255/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5008 - acc: 0.7460 - val_loss: 0.5414 - val_acc: 0.7147\n",
            "Epoch 256/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5007 - acc: 0.7405 - val_loss: 0.5472 - val_acc: 0.7092\n",
            "Epoch 257/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5136 - acc: 0.7398 - val_loss: 0.5459 - val_acc: 0.7092\n",
            "Epoch 258/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4917 - acc: 0.7587 - val_loss: 0.5501 - val_acc: 0.7051\n",
            "Epoch 259/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4990 - acc: 0.7497 - val_loss: 0.5496 - val_acc: 0.7064\n",
            "Epoch 260/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5011 - acc: 0.7470 - val_loss: 0.5401 - val_acc: 0.7051\n",
            "Epoch 261/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5021 - acc: 0.7449 - val_loss: 0.5392 - val_acc: 0.7229\n",
            "Epoch 262/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.4942 - acc: 0.7559 - val_loss: 0.6026 - val_acc: 0.6996\n",
            "Epoch 263/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4956 - acc: 0.7532 - val_loss: 0.5412 - val_acc: 0.7092\n",
            "Epoch 264/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4949 - acc: 0.7484 - val_loss: 0.5673 - val_acc: 0.6941\n",
            "Epoch 265/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5022 - acc: 0.7463 - val_loss: 0.6284 - val_acc: 0.6763\n",
            "Epoch 266/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4986 - acc: 0.7484 - val_loss: 0.5861 - val_acc: 0.6776\n",
            "Epoch 267/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4922 - acc: 0.7552 - val_loss: 0.5431 - val_acc: 0.7160\n",
            "Epoch 268/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4921 - acc: 0.7556 - val_loss: 0.6301 - val_acc: 0.6941\n",
            "Epoch 269/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4994 - acc: 0.7436 - val_loss: 0.5614 - val_acc: 0.7037\n",
            "Epoch 270/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4981 - acc: 0.7570 - val_loss: 0.5389 - val_acc: 0.7119\n",
            "Epoch 271/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4955 - acc: 0.7528 - val_loss: 0.5397 - val_acc: 0.7078\n",
            "Epoch 272/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.5000 - acc: 0.7477 - val_loss: 0.5499 - val_acc: 0.7174\n",
            "Epoch 273/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4894 - acc: 0.7573 - val_loss: 0.5394 - val_acc: 0.7133\n",
            "Epoch 274/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4946 - acc: 0.7491 - val_loss: 0.5587 - val_acc: 0.6968\n",
            "Epoch 275/1000\n",
            "2913/2913 [==============================] - 0s 91us/step - loss: 0.5088 - acc: 0.7470 - val_loss: 0.5383 - val_acc: 0.7215\n",
            "Epoch 276/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4867 - acc: 0.7611 - val_loss: 0.5668 - val_acc: 0.6900\n",
            "Epoch 277/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5033 - acc: 0.7470 - val_loss: 0.5606 - val_acc: 0.6886\n",
            "Epoch 278/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4925 - acc: 0.7549 - val_loss: 0.5699 - val_acc: 0.7064\n",
            "Epoch 279/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4883 - acc: 0.7583 - val_loss: 0.5364 - val_acc: 0.7257\n",
            "Epoch 280/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4954 - acc: 0.7497 - val_loss: 0.5668 - val_acc: 0.7037\n",
            "Epoch 281/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4970 - acc: 0.7449 - val_loss: 0.5512 - val_acc: 0.7064\n",
            "Epoch 282/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4870 - acc: 0.7590 - val_loss: 0.6220 - val_acc: 0.6790\n",
            "Epoch 283/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4896 - acc: 0.7573 - val_loss: 0.5333 - val_acc: 0.7243\n",
            "Epoch 284/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4993 - acc: 0.7504 - val_loss: 0.5372 - val_acc: 0.7215\n",
            "Epoch 285/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4888 - acc: 0.7549 - val_loss: 0.5393 - val_acc: 0.7078\n",
            "Epoch 286/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4891 - acc: 0.7587 - val_loss: 0.5469 - val_acc: 0.7092\n",
            "Epoch 287/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4858 - acc: 0.7545 - val_loss: 0.6952 - val_acc: 0.6639\n",
            "Epoch 288/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4980 - acc: 0.7518 - val_loss: 0.5599 - val_acc: 0.6955\n",
            "Epoch 289/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4877 - acc: 0.7590 - val_loss: 0.5431 - val_acc: 0.7160\n",
            "Epoch 290/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.4897 - acc: 0.7515 - val_loss: 0.5337 - val_acc: 0.7215\n",
            "Epoch 291/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4837 - acc: 0.7576 - val_loss: 0.6669 - val_acc: 0.6310\n",
            "Epoch 292/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.5086 - acc: 0.7528 - val_loss: 0.5411 - val_acc: 0.7188\n",
            "Epoch 293/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4893 - acc: 0.7580 - val_loss: 0.5478 - val_acc: 0.7160\n",
            "Epoch 294/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4820 - acc: 0.7559 - val_loss: 0.5405 - val_acc: 0.7174\n",
            "Epoch 295/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4924 - acc: 0.7436 - val_loss: 0.5419 - val_acc: 0.7174\n",
            "Epoch 296/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4803 - acc: 0.7679 - val_loss: 0.5518 - val_acc: 0.7243\n",
            "Epoch 297/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4876 - acc: 0.7566 - val_loss: 0.5406 - val_acc: 0.7243\n",
            "Epoch 298/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4828 - acc: 0.7614 - val_loss: 0.6119 - val_acc: 0.6845\n",
            "Epoch 299/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.5008 - acc: 0.7587 - val_loss: 0.5374 - val_acc: 0.7188\n",
            "Epoch 300/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4841 - acc: 0.7549 - val_loss: 0.5691 - val_acc: 0.6900\n",
            "Epoch 301/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4931 - acc: 0.7607 - val_loss: 0.5465 - val_acc: 0.7257\n",
            "Epoch 302/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4842 - acc: 0.7614 - val_loss: 0.5564 - val_acc: 0.7092\n",
            "Epoch 303/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.4792 - acc: 0.7618 - val_loss: 0.5314 - val_acc: 0.7284\n",
            "Epoch 304/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4911 - acc: 0.7597 - val_loss: 0.5332 - val_acc: 0.7243\n",
            "Epoch 305/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4823 - acc: 0.7580 - val_loss: 0.5436 - val_acc: 0.7147\n",
            "Epoch 306/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4911 - acc: 0.7607 - val_loss: 0.5539 - val_acc: 0.6996\n",
            "Epoch 307/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4866 - acc: 0.7597 - val_loss: 0.5437 - val_acc: 0.7147\n",
            "Epoch 308/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4824 - acc: 0.7545 - val_loss: 0.5507 - val_acc: 0.7174\n",
            "Epoch 309/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4838 - acc: 0.7628 - val_loss: 0.5455 - val_acc: 0.7023\n",
            "Epoch 310/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4803 - acc: 0.7645 - val_loss: 0.6687 - val_acc: 0.6502\n",
            "Epoch 311/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4911 - acc: 0.7542 - val_loss: 0.5442 - val_acc: 0.7160\n",
            "Epoch 312/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4783 - acc: 0.7638 - val_loss: 0.5625 - val_acc: 0.6914\n",
            "Epoch 313/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4824 - acc: 0.7666 - val_loss: 0.5412 - val_acc: 0.7106\n",
            "Epoch 314/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4918 - acc: 0.7545 - val_loss: 0.5352 - val_acc: 0.7202\n",
            "Epoch 315/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4738 - acc: 0.7707 - val_loss: 0.5342 - val_acc: 0.7284\n",
            "Epoch 316/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4992 - acc: 0.7600 - val_loss: 0.5332 - val_acc: 0.7229\n",
            "Epoch 317/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4792 - acc: 0.7631 - val_loss: 0.5409 - val_acc: 0.7243\n",
            "Epoch 318/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4817 - acc: 0.7559 - val_loss: 0.5350 - val_acc: 0.7257\n",
            "Epoch 319/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4805 - acc: 0.7535 - val_loss: 0.5305 - val_acc: 0.7270\n",
            "Epoch 320/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4827 - acc: 0.7618 - val_loss: 0.5375 - val_acc: 0.7339\n",
            "Epoch 321/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4760 - acc: 0.7618 - val_loss: 0.5408 - val_acc: 0.7202\n",
            "Epoch 322/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4883 - acc: 0.7535 - val_loss: 0.5302 - val_acc: 0.7353\n",
            "Epoch 323/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4711 - acc: 0.7669 - val_loss: 0.5348 - val_acc: 0.7174\n",
            "Epoch 324/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4795 - acc: 0.7576 - val_loss: 0.5513 - val_acc: 0.6982\n",
            "Epoch 325/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4901 - acc: 0.7621 - val_loss: 0.5415 - val_acc: 0.7229\n",
            "Epoch 326/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4701 - acc: 0.7741 - val_loss: 0.5317 - val_acc: 0.7284\n",
            "Epoch 327/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4786 - acc: 0.7614 - val_loss: 0.5359 - val_acc: 0.7243\n",
            "Epoch 328/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4699 - acc: 0.7707 - val_loss: 0.5386 - val_acc: 0.7202\n",
            "Epoch 329/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4843 - acc: 0.7697 - val_loss: 0.5310 - val_acc: 0.7380\n",
            "Epoch 330/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4728 - acc: 0.7648 - val_loss: 0.5295 - val_acc: 0.7380\n",
            "Epoch 331/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4721 - acc: 0.7642 - val_loss: 0.6506 - val_acc: 0.6831\n",
            "Epoch 332/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4965 - acc: 0.7480 - val_loss: 0.5421 - val_acc: 0.7188\n",
            "Epoch 333/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4776 - acc: 0.7580 - val_loss: 0.5303 - val_acc: 0.7270\n",
            "Epoch 334/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4713 - acc: 0.7748 - val_loss: 0.5393 - val_acc: 0.7133\n",
            "Epoch 335/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4859 - acc: 0.7576 - val_loss: 0.5302 - val_acc: 0.7257\n",
            "Epoch 336/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4703 - acc: 0.7669 - val_loss: 0.6004 - val_acc: 0.6722\n",
            "Epoch 337/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4784 - acc: 0.7611 - val_loss: 0.5288 - val_acc: 0.7311\n",
            "Epoch 338/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4756 - acc: 0.7734 - val_loss: 0.5477 - val_acc: 0.7133\n",
            "Epoch 339/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4732 - acc: 0.7642 - val_loss: 0.5363 - val_acc: 0.7229\n",
            "Epoch 340/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4717 - acc: 0.7624 - val_loss: 0.5683 - val_acc: 0.6914\n",
            "Epoch 341/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4707 - acc: 0.7590 - val_loss: 0.5622 - val_acc: 0.6927\n",
            "Epoch 342/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4888 - acc: 0.7497 - val_loss: 0.5347 - val_acc: 0.7229\n",
            "Epoch 343/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4762 - acc: 0.7631 - val_loss: 0.5437 - val_acc: 0.7078\n",
            "Epoch 344/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4706 - acc: 0.7652 - val_loss: 0.5308 - val_acc: 0.7380\n",
            "Epoch 345/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4698 - acc: 0.7707 - val_loss: 0.5265 - val_acc: 0.7339\n",
            "Epoch 346/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4745 - acc: 0.7635 - val_loss: 0.5290 - val_acc: 0.7366\n",
            "Epoch 347/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4724 - acc: 0.7659 - val_loss: 0.5479 - val_acc: 0.7106\n",
            "Epoch 348/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4664 - acc: 0.7690 - val_loss: 0.5856 - val_acc: 0.6941\n",
            "Epoch 349/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4789 - acc: 0.7662 - val_loss: 0.5467 - val_acc: 0.7023\n",
            "Epoch 350/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4630 - acc: 0.7724 - val_loss: 0.5403 - val_acc: 0.7215\n",
            "Epoch 351/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4753 - acc: 0.7703 - val_loss: 0.5620 - val_acc: 0.6900\n",
            "Epoch 352/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4725 - acc: 0.7686 - val_loss: 0.5322 - val_acc: 0.7311\n",
            "Epoch 353/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4783 - acc: 0.7614 - val_loss: 0.5605 - val_acc: 0.6941\n",
            "Epoch 354/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4682 - acc: 0.7714 - val_loss: 0.5580 - val_acc: 0.6982\n",
            "Epoch 355/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4754 - acc: 0.7683 - val_loss: 0.5582 - val_acc: 0.7119\n",
            "Epoch 356/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4763 - acc: 0.7700 - val_loss: 0.5354 - val_acc: 0.7270\n",
            "Epoch 357/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4688 - acc: 0.7666 - val_loss: 0.5478 - val_acc: 0.6982\n",
            "Epoch 358/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4722 - acc: 0.7710 - val_loss: 0.6467 - val_acc: 0.7160\n",
            "Epoch 359/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4729 - acc: 0.7679 - val_loss: 0.5500 - val_acc: 0.7284\n",
            "Epoch 360/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4666 - acc: 0.7618 - val_loss: 0.5303 - val_acc: 0.7366\n",
            "Epoch 361/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4619 - acc: 0.7748 - val_loss: 0.5455 - val_acc: 0.7133\n",
            "Epoch 362/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4777 - acc: 0.7669 - val_loss: 0.5734 - val_acc: 0.7106\n",
            "Epoch 363/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4620 - acc: 0.7727 - val_loss: 0.5290 - val_acc: 0.7257\n",
            "Epoch 364/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4692 - acc: 0.7666 - val_loss: 0.5762 - val_acc: 0.7023\n",
            "Epoch 365/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4680 - acc: 0.7710 - val_loss: 0.5460 - val_acc: 0.7078\n",
            "Epoch 366/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4705 - acc: 0.7700 - val_loss: 0.5651 - val_acc: 0.7188\n",
            "Epoch 367/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4662 - acc: 0.7693 - val_loss: 0.5402 - val_acc: 0.7311\n",
            "Epoch 368/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4663 - acc: 0.7652 - val_loss: 0.5291 - val_acc: 0.7353\n",
            "Epoch 369/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4628 - acc: 0.7703 - val_loss: 0.5259 - val_acc: 0.7339\n",
            "Epoch 370/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4706 - acc: 0.7703 - val_loss: 0.5387 - val_acc: 0.7270\n",
            "Epoch 371/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4680 - acc: 0.7676 - val_loss: 0.5332 - val_acc: 0.7325\n",
            "Epoch 372/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4596 - acc: 0.7789 - val_loss: 0.5564 - val_acc: 0.7092\n",
            "Epoch 373/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4569 - acc: 0.7758 - val_loss: 0.5757 - val_acc: 0.6968\n",
            "Epoch 374/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4734 - acc: 0.7618 - val_loss: 0.5352 - val_acc: 0.7325\n",
            "Epoch 375/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4570 - acc: 0.7741 - val_loss: 0.5717 - val_acc: 0.7010\n",
            "Epoch 376/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4707 - acc: 0.7707 - val_loss: 0.6137 - val_acc: 0.7051\n",
            "Epoch 377/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4707 - acc: 0.7638 - val_loss: 0.5292 - val_acc: 0.7257\n",
            "Epoch 378/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4554 - acc: 0.7820 - val_loss: 0.5231 - val_acc: 0.7407\n",
            "Epoch 379/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4764 - acc: 0.7655 - val_loss: 0.5239 - val_acc: 0.7366\n",
            "Epoch 380/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4546 - acc: 0.7803 - val_loss: 0.5231 - val_acc: 0.7366\n",
            "Epoch 381/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4640 - acc: 0.7686 - val_loss: 0.6791 - val_acc: 0.6886\n",
            "Epoch 382/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4649 - acc: 0.7837 - val_loss: 0.5240 - val_acc: 0.7394\n",
            "Epoch 383/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4588 - acc: 0.7707 - val_loss: 0.5262 - val_acc: 0.7380\n",
            "Epoch 384/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4769 - acc: 0.7556 - val_loss: 0.5360 - val_acc: 0.7339\n",
            "Epoch 385/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4585 - acc: 0.7700 - val_loss: 0.5693 - val_acc: 0.7133\n",
            "Epoch 386/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4609 - acc: 0.7697 - val_loss: 0.5457 - val_acc: 0.7339\n",
            "Epoch 387/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4580 - acc: 0.7841 - val_loss: 0.5329 - val_acc: 0.7339\n",
            "Epoch 388/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4634 - acc: 0.7659 - val_loss: 0.5864 - val_acc: 0.7229\n",
            "Epoch 389/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4675 - acc: 0.7758 - val_loss: 0.5369 - val_acc: 0.7284\n",
            "Epoch 390/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4677 - acc: 0.7697 - val_loss: 0.5352 - val_acc: 0.7298\n",
            "Epoch 391/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4500 - acc: 0.7868 - val_loss: 0.5635 - val_acc: 0.7023\n",
            "Epoch 392/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4734 - acc: 0.7597 - val_loss: 0.5447 - val_acc: 0.7202\n",
            "Epoch 393/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4503 - acc: 0.7779 - val_loss: 0.5345 - val_acc: 0.7407\n",
            "Epoch 394/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4674 - acc: 0.7745 - val_loss: 0.5345 - val_acc: 0.7298\n",
            "Epoch 395/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4620 - acc: 0.7748 - val_loss: 0.5360 - val_acc: 0.7298\n",
            "Epoch 396/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4622 - acc: 0.7714 - val_loss: 0.5243 - val_acc: 0.7366\n",
            "Epoch 397/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4546 - acc: 0.7769 - val_loss: 0.5943 - val_acc: 0.6886\n",
            "Epoch 398/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4658 - acc: 0.7745 - val_loss: 0.5218 - val_acc: 0.7380\n",
            "Epoch 399/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4508 - acc: 0.7875 - val_loss: 0.5239 - val_acc: 0.7394\n",
            "Epoch 400/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4624 - acc: 0.7765 - val_loss: 0.5587 - val_acc: 0.7339\n",
            "Epoch 401/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4550 - acc: 0.7748 - val_loss: 0.5368 - val_acc: 0.7270\n",
            "Epoch 402/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4461 - acc: 0.7817 - val_loss: 0.5414 - val_acc: 0.7174\n",
            "Epoch 403/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4708 - acc: 0.7611 - val_loss: 0.5270 - val_acc: 0.7298\n",
            "Epoch 404/1000\n",
            "2913/2913 [==============================] - 0s 91us/step - loss: 0.4597 - acc: 0.7789 - val_loss: 0.5298 - val_acc: 0.7311\n",
            "Epoch 405/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4502 - acc: 0.7796 - val_loss: 0.5418 - val_acc: 0.7257\n",
            "Epoch 406/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4575 - acc: 0.7710 - val_loss: 0.5313 - val_acc: 0.7339\n",
            "Epoch 407/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4761 - acc: 0.7673 - val_loss: 0.5368 - val_acc: 0.7298\n",
            "Epoch 408/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4473 - acc: 0.7844 - val_loss: 0.6024 - val_acc: 0.6900\n",
            "Epoch 409/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4575 - acc: 0.7738 - val_loss: 0.5237 - val_acc: 0.7325\n",
            "Epoch 410/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.4533 - acc: 0.7738 - val_loss: 0.5335 - val_acc: 0.7257\n",
            "Epoch 411/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4544 - acc: 0.7758 - val_loss: 0.5373 - val_acc: 0.7298\n",
            "Epoch 412/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4584 - acc: 0.7714 - val_loss: 0.5343 - val_acc: 0.7257\n",
            "Epoch 413/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4577 - acc: 0.7810 - val_loss: 0.5247 - val_acc: 0.7407\n",
            "Epoch 414/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4681 - acc: 0.7707 - val_loss: 0.5460 - val_acc: 0.7092\n",
            "Epoch 415/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4468 - acc: 0.7789 - val_loss: 0.5202 - val_acc: 0.7435\n",
            "Epoch 416/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4512 - acc: 0.7745 - val_loss: 0.5420 - val_acc: 0.7394\n",
            "Epoch 417/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4577 - acc: 0.7748 - val_loss: 0.5656 - val_acc: 0.7215\n",
            "Epoch 418/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4586 - acc: 0.7824 - val_loss: 0.5356 - val_acc: 0.7311\n",
            "Epoch 419/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4676 - acc: 0.7755 - val_loss: 0.6091 - val_acc: 0.7188\n",
            "Epoch 420/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4502 - acc: 0.7889 - val_loss: 0.5226 - val_acc: 0.7449\n",
            "Epoch 421/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4452 - acc: 0.7872 - val_loss: 0.5269 - val_acc: 0.7394\n",
            "Epoch 422/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4582 - acc: 0.7800 - val_loss: 0.5273 - val_acc: 0.7353\n",
            "Epoch 423/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4534 - acc: 0.7717 - val_loss: 0.5623 - val_acc: 0.7078\n",
            "Epoch 424/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4667 - acc: 0.7810 - val_loss: 0.5534 - val_acc: 0.7311\n",
            "Epoch 425/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4443 - acc: 0.7885 - val_loss: 0.5220 - val_acc: 0.7462\n",
            "Epoch 426/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4449 - acc: 0.7854 - val_loss: 0.5214 - val_acc: 0.7517\n",
            "Epoch 427/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4754 - acc: 0.7614 - val_loss: 0.5219 - val_acc: 0.7449\n",
            "Epoch 428/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4413 - acc: 0.7868 - val_loss: 0.5248 - val_acc: 0.7366\n",
            "Epoch 429/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4489 - acc: 0.7803 - val_loss: 0.5328 - val_acc: 0.7325\n",
            "Epoch 430/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4538 - acc: 0.7796 - val_loss: 0.5250 - val_acc: 0.7421\n",
            "Epoch 431/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4441 - acc: 0.7796 - val_loss: 0.5500 - val_acc: 0.7078\n",
            "Epoch 432/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4642 - acc: 0.7710 - val_loss: 0.5291 - val_acc: 0.7353\n",
            "Epoch 433/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4429 - acc: 0.7848 - val_loss: 0.5652 - val_acc: 0.7133\n",
            "Epoch 434/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4535 - acc: 0.7755 - val_loss: 0.6797 - val_acc: 0.7010\n",
            "Epoch 435/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4513 - acc: 0.7793 - val_loss: 0.5197 - val_acc: 0.7462\n",
            "Epoch 436/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4480 - acc: 0.7782 - val_loss: 0.6650 - val_acc: 0.6694\n",
            "Epoch 437/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4576 - acc: 0.7810 - val_loss: 0.5222 - val_acc: 0.7435\n",
            "Epoch 438/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4478 - acc: 0.7772 - val_loss: 0.5242 - val_acc: 0.7449\n",
            "Epoch 439/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4587 - acc: 0.7738 - val_loss: 0.5334 - val_acc: 0.7339\n",
            "Epoch 440/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4397 - acc: 0.7913 - val_loss: 0.5209 - val_acc: 0.7366\n",
            "Epoch 441/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4469 - acc: 0.7779 - val_loss: 0.5950 - val_acc: 0.7229\n",
            "Epoch 442/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4642 - acc: 0.7779 - val_loss: 0.5194 - val_acc: 0.7490\n",
            "Epoch 443/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4459 - acc: 0.7813 - val_loss: 0.5409 - val_acc: 0.7160\n",
            "Epoch 444/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4529 - acc: 0.7758 - val_loss: 0.5700 - val_acc: 0.7174\n",
            "Epoch 445/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4389 - acc: 0.7868 - val_loss: 0.5267 - val_acc: 0.7449\n",
            "Epoch 446/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4475 - acc: 0.7793 - val_loss: 0.5162 - val_acc: 0.7476\n",
            "Epoch 447/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4562 - acc: 0.7734 - val_loss: 0.5180 - val_acc: 0.7421\n",
            "Epoch 448/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4360 - acc: 0.7903 - val_loss: 0.7184 - val_acc: 0.6818\n",
            "Epoch 449/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4508 - acc: 0.7824 - val_loss: 0.5353 - val_acc: 0.7229\n",
            "Epoch 450/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4438 - acc: 0.7793 - val_loss: 0.5473 - val_acc: 0.7394\n",
            "Epoch 451/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4457 - acc: 0.7885 - val_loss: 0.5174 - val_acc: 0.7353\n",
            "Epoch 452/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4405 - acc: 0.7817 - val_loss: 0.5424 - val_acc: 0.7311\n",
            "Epoch 453/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4509 - acc: 0.7830 - val_loss: 0.5334 - val_acc: 0.7270\n",
            "Epoch 454/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4403 - acc: 0.7868 - val_loss: 0.5670 - val_acc: 0.6941\n",
            "Epoch 455/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4446 - acc: 0.7837 - val_loss: 0.5678 - val_acc: 0.7037\n",
            "Epoch 456/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4431 - acc: 0.7810 - val_loss: 0.5210 - val_acc: 0.7490\n",
            "Epoch 457/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4390 - acc: 0.7882 - val_loss: 0.5425 - val_acc: 0.7119\n",
            "Epoch 458/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4549 - acc: 0.7769 - val_loss: 0.5265 - val_acc: 0.7298\n",
            "Epoch 459/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4382 - acc: 0.7906 - val_loss: 0.5278 - val_acc: 0.7421\n",
            "Epoch 460/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4512 - acc: 0.7817 - val_loss: 0.5337 - val_acc: 0.7449\n",
            "Epoch 461/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4376 - acc: 0.7878 - val_loss: 0.5188 - val_acc: 0.7435\n",
            "Epoch 462/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4361 - acc: 0.7896 - val_loss: 0.5190 - val_acc: 0.7490\n",
            "Epoch 463/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4566 - acc: 0.7786 - val_loss: 0.5157 - val_acc: 0.7476\n",
            "Epoch 464/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4367 - acc: 0.7920 - val_loss: 0.5395 - val_acc: 0.7243\n",
            "Epoch 465/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4358 - acc: 0.7933 - val_loss: 0.5322 - val_acc: 0.7229\n",
            "Epoch 466/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4374 - acc: 0.7892 - val_loss: 0.6971 - val_acc: 0.6914\n",
            "Epoch 467/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4574 - acc: 0.7923 - val_loss: 0.5175 - val_acc: 0.7421\n",
            "Epoch 468/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4379 - acc: 0.7868 - val_loss: 0.5250 - val_acc: 0.7380\n",
            "Epoch 469/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4500 - acc: 0.7810 - val_loss: 0.5136 - val_acc: 0.7545\n",
            "Epoch 470/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4294 - acc: 0.7975 - val_loss: 0.5280 - val_acc: 0.7394\n",
            "Epoch 471/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4307 - acc: 0.7865 - val_loss: 0.5288 - val_acc: 0.7449\n",
            "Epoch 472/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4554 - acc: 0.7854 - val_loss: 0.5152 - val_acc: 0.7407\n",
            "Epoch 473/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4315 - acc: 0.7933 - val_loss: 0.5140 - val_acc: 0.7490\n",
            "Epoch 474/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4532 - acc: 0.7707 - val_loss: 0.5150 - val_acc: 0.7449\n",
            "Epoch 475/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4368 - acc: 0.7899 - val_loss: 0.5486 - val_acc: 0.7064\n",
            "Epoch 476/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4421 - acc: 0.7837 - val_loss: 0.5327 - val_acc: 0.7215\n",
            "Epoch 477/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4297 - acc: 0.7920 - val_loss: 0.5294 - val_acc: 0.7407\n",
            "Epoch 478/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4448 - acc: 0.7889 - val_loss: 0.5115 - val_acc: 0.7572\n",
            "Epoch 479/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4447 - acc: 0.7738 - val_loss: 0.5275 - val_acc: 0.7517\n",
            "Epoch 480/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4298 - acc: 0.7978 - val_loss: 0.5255 - val_acc: 0.7339\n",
            "Epoch 481/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4416 - acc: 0.7872 - val_loss: 0.5291 - val_acc: 0.7449\n",
            "Epoch 482/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4308 - acc: 0.7937 - val_loss: 0.5194 - val_acc: 0.7449\n",
            "Epoch 483/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4445 - acc: 0.7786 - val_loss: 0.5301 - val_acc: 0.7298\n",
            "Epoch 484/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.5304 - val_acc: 0.7298\n",
            "Epoch 485/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4335 - acc: 0.7885 - val_loss: 0.5317 - val_acc: 0.7476\n",
            "Epoch 486/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4473 - acc: 0.7844 - val_loss: 0.5277 - val_acc: 0.7325\n",
            "Epoch 487/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4278 - acc: 0.7971 - val_loss: 0.5297 - val_acc: 0.7311\n",
            "Epoch 488/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4305 - acc: 0.7947 - val_loss: 0.5482 - val_acc: 0.7133\n",
            "Epoch 489/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4501 - acc: 0.7734 - val_loss: 0.5362 - val_acc: 0.7449\n",
            "Epoch 490/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4303 - acc: 0.7988 - val_loss: 0.5184 - val_acc: 0.7476\n",
            "Epoch 491/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4388 - acc: 0.7885 - val_loss: 0.5163 - val_acc: 0.7503\n",
            "Epoch 492/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4281 - acc: 0.7947 - val_loss: 0.5181 - val_acc: 0.7449\n",
            "Epoch 493/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4458 - acc: 0.7927 - val_loss: 0.5354 - val_acc: 0.7202\n",
            "Epoch 494/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4412 - acc: 0.7865 - val_loss: 0.5214 - val_acc: 0.7394\n",
            "Epoch 495/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4332 - acc: 0.7930 - val_loss: 0.5417 - val_acc: 0.7503\n",
            "Epoch 496/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4299 - acc: 0.7930 - val_loss: 0.6224 - val_acc: 0.7023\n",
            "Epoch 497/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4335 - acc: 0.7844 - val_loss: 0.5206 - val_acc: 0.7490\n",
            "Epoch 498/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4410 - acc: 0.7878 - val_loss: 0.5161 - val_acc: 0.7490\n",
            "Epoch 499/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4368 - acc: 0.7930 - val_loss: 0.5269 - val_acc: 0.7435\n",
            "Epoch 500/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4234 - acc: 0.7964 - val_loss: 0.5365 - val_acc: 0.7202\n",
            "Epoch 501/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4374 - acc: 0.7810 - val_loss: 0.5134 - val_acc: 0.7490\n",
            "Epoch 502/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4355 - acc: 0.7882 - val_loss: 0.5204 - val_acc: 0.7421\n",
            "Epoch 503/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4281 - acc: 0.7992 - val_loss: 0.5825 - val_acc: 0.7257\n",
            "Epoch 504/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4309 - acc: 0.7920 - val_loss: 0.5118 - val_acc: 0.7531\n",
            "Epoch 505/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4266 - acc: 0.7933 - val_loss: 0.5253 - val_acc: 0.7394\n",
            "Epoch 506/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4370 - acc: 0.7872 - val_loss: 0.6237 - val_acc: 0.7051\n",
            "Epoch 507/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4340 - acc: 0.7920 - val_loss: 0.5207 - val_acc: 0.7476\n",
            "Epoch 508/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4260 - acc: 0.7916 - val_loss: 0.5128 - val_acc: 0.7531\n",
            "Epoch 509/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4225 - acc: 0.8098 - val_loss: 0.5458 - val_acc: 0.7133\n",
            "Epoch 510/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4373 - acc: 0.7844 - val_loss: 0.5326 - val_acc: 0.7531\n",
            "Epoch 511/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4369 - acc: 0.7899 - val_loss: 0.5145 - val_acc: 0.7490\n",
            "Epoch 512/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4232 - acc: 0.7947 - val_loss: 0.5659 - val_acc: 0.7010\n",
            "Epoch 513/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4295 - acc: 0.7875 - val_loss: 0.5135 - val_acc: 0.7517\n",
            "Epoch 514/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4346 - acc: 0.7927 - val_loss: 0.5118 - val_acc: 0.7572\n",
            "Epoch 515/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4283 - acc: 0.7964 - val_loss: 0.5157 - val_acc: 0.7490\n",
            "Epoch 516/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4281 - acc: 0.7930 - val_loss: 0.5086 - val_acc: 0.7599\n",
            "Epoch 517/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4232 - acc: 0.8009 - val_loss: 0.7073 - val_acc: 0.6818\n",
            "Epoch 518/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4375 - acc: 0.7837 - val_loss: 0.5329 - val_acc: 0.7257\n",
            "Epoch 519/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.4271 - acc: 0.7933 - val_loss: 0.5116 - val_acc: 0.7586\n",
            "Epoch 520/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4402 - acc: 0.7889 - val_loss: 0.5158 - val_acc: 0.7449\n",
            "Epoch 521/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4203 - acc: 0.8012 - val_loss: 0.5101 - val_acc: 0.7517\n",
            "Epoch 522/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4318 - acc: 0.7889 - val_loss: 0.5312 - val_acc: 0.7257\n",
            "Epoch 523/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4397 - acc: 0.7985 - val_loss: 0.5113 - val_acc: 0.7531\n",
            "Epoch 524/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4251 - acc: 0.7968 - val_loss: 0.6026 - val_acc: 0.6955\n",
            "Epoch 525/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4295 - acc: 0.7971 - val_loss: 0.5105 - val_acc: 0.7531\n",
            "Epoch 526/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4238 - acc: 0.7961 - val_loss: 0.5069 - val_acc: 0.7586\n",
            "Epoch 527/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4307 - acc: 0.8002 - val_loss: 0.5098 - val_acc: 0.7627\n",
            "Epoch 528/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4236 - acc: 0.7999 - val_loss: 0.5557 - val_acc: 0.7078\n",
            "Epoch 529/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4325 - acc: 0.7933 - val_loss: 0.5431 - val_acc: 0.7188\n",
            "Epoch 530/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4189 - acc: 0.7999 - val_loss: 0.5082 - val_acc: 0.7490\n",
            "Epoch 531/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4214 - acc: 0.8005 - val_loss: 0.5513 - val_acc: 0.7229\n",
            "Epoch 532/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4333 - acc: 0.7844 - val_loss: 0.5391 - val_acc: 0.7490\n",
            "Epoch 533/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4192 - acc: 0.8057 - val_loss: 0.6320 - val_acc: 0.6804\n",
            "Epoch 534/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4246 - acc: 0.7961 - val_loss: 0.6998 - val_acc: 0.7064\n",
            "Epoch 535/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4298 - acc: 0.7988 - val_loss: 0.5321 - val_acc: 0.7202\n",
            "Epoch 536/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4323 - acc: 0.7837 - val_loss: 0.5424 - val_acc: 0.7270\n",
            "Epoch 537/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4247 - acc: 0.7940 - val_loss: 0.5173 - val_acc: 0.7613\n",
            "Epoch 538/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4346 - acc: 0.7933 - val_loss: 0.5451 - val_acc: 0.7284\n",
            "Epoch 539/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4207 - acc: 0.7992 - val_loss: 0.5236 - val_acc: 0.7531\n",
            "Epoch 540/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4215 - acc: 0.8002 - val_loss: 0.6001 - val_acc: 0.7064\n",
            "Epoch 541/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4247 - acc: 0.7988 - val_loss: 0.5411 - val_acc: 0.7174\n",
            "Epoch 542/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4287 - acc: 0.7909 - val_loss: 0.5271 - val_acc: 0.7284\n",
            "Epoch 543/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4171 - acc: 0.8030 - val_loss: 0.5292 - val_acc: 0.7325\n",
            "Epoch 544/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4317 - acc: 0.7927 - val_loss: 0.5102 - val_acc: 0.7599\n",
            "Epoch 545/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4257 - acc: 0.7947 - val_loss: 0.5756 - val_acc: 0.7421\n",
            "Epoch 546/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4206 - acc: 0.8043 - val_loss: 0.5350 - val_acc: 0.7229\n",
            "Epoch 547/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4229 - acc: 0.7968 - val_loss: 0.5092 - val_acc: 0.7586\n",
            "Epoch 548/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4375 - acc: 0.7903 - val_loss: 0.5237 - val_acc: 0.7462\n",
            "Epoch 549/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4107 - acc: 0.8057 - val_loss: 0.5064 - val_acc: 0.7599\n",
            "Epoch 550/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4282 - acc: 0.7878 - val_loss: 0.5141 - val_acc: 0.7421\n",
            "Epoch 551/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4280 - acc: 0.7964 - val_loss: 0.5127 - val_acc: 0.7449\n",
            "Epoch 552/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4228 - acc: 0.8026 - val_loss: 0.6078 - val_acc: 0.7188\n",
            "Epoch 553/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4165 - acc: 0.7951 - val_loss: 0.5097 - val_acc: 0.7517\n",
            "Epoch 554/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4170 - acc: 0.7968 - val_loss: 0.5421 - val_acc: 0.7174\n",
            "Epoch 555/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4252 - acc: 0.7981 - val_loss: 0.5154 - val_acc: 0.7558\n",
            "Epoch 556/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4209 - acc: 0.8019 - val_loss: 0.5167 - val_acc: 0.7435\n",
            "Epoch 557/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4238 - acc: 0.7964 - val_loss: 0.5173 - val_acc: 0.7394\n",
            "Epoch 558/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4161 - acc: 0.8036 - val_loss: 0.6090 - val_acc: 0.7380\n",
            "Epoch 559/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4197 - acc: 0.7933 - val_loss: 0.5136 - val_acc: 0.7517\n",
            "Epoch 560/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4209 - acc: 0.8016 - val_loss: 0.5649 - val_acc: 0.7311\n",
            "Epoch 561/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4302 - acc: 0.8005 - val_loss: 0.5450 - val_acc: 0.7133\n",
            "Epoch 562/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4196 - acc: 0.7995 - val_loss: 0.6105 - val_acc: 0.7325\n",
            "Epoch 563/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4256 - acc: 0.8040 - val_loss: 0.5085 - val_acc: 0.7599\n",
            "Epoch 564/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4210 - acc: 0.7978 - val_loss: 0.5391 - val_acc: 0.7174\n",
            "Epoch 565/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4223 - acc: 0.7964 - val_loss: 0.5200 - val_acc: 0.7325\n",
            "Epoch 566/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4187 - acc: 0.7954 - val_loss: 0.6549 - val_acc: 0.7106\n",
            "Epoch 567/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4186 - acc: 0.8067 - val_loss: 0.5200 - val_acc: 0.7380\n",
            "Epoch 568/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4277 - acc: 0.7896 - val_loss: 0.5163 - val_acc: 0.7558\n",
            "Epoch 569/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4155 - acc: 0.8050 - val_loss: 0.5272 - val_acc: 0.7339\n",
            "Epoch 570/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4139 - acc: 0.8016 - val_loss: 0.5058 - val_acc: 0.7613\n",
            "Epoch 571/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4244 - acc: 0.8009 - val_loss: 0.5310 - val_acc: 0.7270\n",
            "Epoch 572/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4107 - acc: 0.8119 - val_loss: 0.5097 - val_acc: 0.7545\n",
            "Epoch 573/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4259 - acc: 0.7878 - val_loss: 0.5090 - val_acc: 0.7517\n",
            "Epoch 574/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4197 - acc: 0.8036 - val_loss: 0.5118 - val_acc: 0.7490\n",
            "Epoch 575/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4078 - acc: 0.8091 - val_loss: 0.6049 - val_acc: 0.6955\n",
            "Epoch 576/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4183 - acc: 0.8040 - val_loss: 0.7097 - val_acc: 0.6749\n",
            "Epoch 577/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4251 - acc: 0.7978 - val_loss: 0.5168 - val_acc: 0.7435\n",
            "Epoch 578/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4094 - acc: 0.8050 - val_loss: 0.5429 - val_acc: 0.7572\n",
            "Epoch 579/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4143 - acc: 0.8026 - val_loss: 0.5477 - val_acc: 0.7119\n",
            "Epoch 580/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4245 - acc: 0.7889 - val_loss: 0.5046 - val_acc: 0.7627\n",
            "Epoch 581/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4232 - acc: 0.7992 - val_loss: 0.5093 - val_acc: 0.7476\n",
            "Epoch 582/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4122 - acc: 0.8016 - val_loss: 0.5351 - val_acc: 0.7586\n",
            "Epoch 583/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4252 - acc: 0.8064 - val_loss: 0.5140 - val_acc: 0.7449\n",
            "Epoch 584/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4124 - acc: 0.7992 - val_loss: 0.5269 - val_acc: 0.7270\n",
            "Epoch 585/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4413 - acc: 0.8005 - val_loss: 0.5049 - val_acc: 0.7613\n",
            "Epoch 586/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.4038 - acc: 0.8043 - val_loss: 0.5130 - val_acc: 0.7490\n",
            "Epoch 587/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4157 - acc: 0.7995 - val_loss: 0.5520 - val_acc: 0.7106\n",
            "Epoch 588/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4140 - acc: 0.8009 - val_loss: 0.5773 - val_acc: 0.7380\n",
            "Epoch 589/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4150 - acc: 0.8023 - val_loss: 0.5140 - val_acc: 0.7531\n",
            "Epoch 590/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4127 - acc: 0.8030 - val_loss: 0.5918 - val_acc: 0.7435\n",
            "Epoch 591/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4146 - acc: 0.8026 - val_loss: 0.5518 - val_acc: 0.7119\n",
            "Epoch 592/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4100 - acc: 0.7988 - val_loss: 0.6026 - val_acc: 0.7023\n",
            "Epoch 593/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.4234 - acc: 0.7930 - val_loss: 0.5105 - val_acc: 0.7476\n",
            "Epoch 594/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4067 - acc: 0.8095 - val_loss: 0.5113 - val_acc: 0.7572\n",
            "Epoch 595/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4242 - acc: 0.7999 - val_loss: 0.5261 - val_acc: 0.7311\n",
            "Epoch 596/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4191 - acc: 0.7981 - val_loss: 0.5088 - val_acc: 0.7558\n",
            "Epoch 597/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4041 - acc: 0.8108 - val_loss: 0.5303 - val_acc: 0.7407\n",
            "Epoch 598/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4089 - acc: 0.8064 - val_loss: 0.5050 - val_acc: 0.7586\n",
            "Epoch 599/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.4151 - acc: 0.8026 - val_loss: 0.5158 - val_acc: 0.7503\n",
            "Epoch 600/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4064 - acc: 0.8023 - val_loss: 0.5043 - val_acc: 0.7627\n",
            "Epoch 601/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4173 - acc: 0.7999 - val_loss: 0.5038 - val_acc: 0.7641\n",
            "Epoch 602/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4039 - acc: 0.7999 - val_loss: 0.5673 - val_acc: 0.7174\n",
            "Epoch 603/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4096 - acc: 0.8033 - val_loss: 0.5441 - val_acc: 0.7202\n",
            "Epoch 604/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4246 - acc: 0.7933 - val_loss: 0.5024 - val_acc: 0.7613\n",
            "Epoch 605/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4020 - acc: 0.8143 - val_loss: 0.5503 - val_acc: 0.7270\n",
            "Epoch 606/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4155 - acc: 0.7992 - val_loss: 0.5260 - val_acc: 0.7284\n",
            "Epoch 607/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4155 - acc: 0.8036 - val_loss: 0.5233 - val_acc: 0.7353\n",
            "Epoch 608/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4027 - acc: 0.8115 - val_loss: 0.5831 - val_acc: 0.7188\n",
            "Epoch 609/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4117 - acc: 0.8057 - val_loss: 0.5305 - val_acc: 0.7243\n",
            "Epoch 610/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4111 - acc: 0.8040 - val_loss: 0.6644 - val_acc: 0.7147\n",
            "Epoch 611/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4197 - acc: 0.8050 - val_loss: 0.5352 - val_acc: 0.7284\n",
            "Epoch 612/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4012 - acc: 0.8098 - val_loss: 0.5040 - val_acc: 0.7641\n",
            "Epoch 613/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4202 - acc: 0.7947 - val_loss: 0.5202 - val_acc: 0.7366\n",
            "Epoch 614/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3997 - acc: 0.8119 - val_loss: 0.5583 - val_acc: 0.7174\n",
            "Epoch 615/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4069 - acc: 0.8054 - val_loss: 0.5206 - val_acc: 0.7421\n",
            "Epoch 616/1000\n",
            "2913/2913 [==============================] - 0s 79us/step - loss: 0.4195 - acc: 0.7964 - val_loss: 0.5276 - val_acc: 0.7476\n",
            "Epoch 617/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3985 - acc: 0.8122 - val_loss: 0.5379 - val_acc: 0.7215\n",
            "Epoch 618/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4090 - acc: 0.8091 - val_loss: 0.5984 - val_acc: 0.7298\n",
            "Epoch 619/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4052 - acc: 0.8108 - val_loss: 0.5077 - val_acc: 0.7503\n",
            "Epoch 620/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4138 - acc: 0.8047 - val_loss: 0.5485 - val_acc: 0.7202\n",
            "Epoch 621/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4085 - acc: 0.8030 - val_loss: 0.5704 - val_acc: 0.7284\n",
            "Epoch 622/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4144 - acc: 0.8050 - val_loss: 0.5280 - val_acc: 0.7380\n",
            "Epoch 623/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3995 - acc: 0.8091 - val_loss: 0.5059 - val_acc: 0.7613\n",
            "Epoch 624/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4091 - acc: 0.8071 - val_loss: 0.5029 - val_acc: 0.7641\n",
            "Epoch 625/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4058 - acc: 0.8122 - val_loss: 0.5434 - val_acc: 0.7339\n",
            "Epoch 626/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.4193 - acc: 0.8054 - val_loss: 0.5719 - val_acc: 0.7119\n",
            "Epoch 627/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4059 - acc: 0.8047 - val_loss: 0.5283 - val_acc: 0.7394\n",
            "Epoch 628/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4099 - acc: 0.8023 - val_loss: 0.5339 - val_acc: 0.7215\n",
            "Epoch 629/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4025 - acc: 0.8067 - val_loss: 0.5123 - val_acc: 0.7462\n",
            "Epoch 630/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4005 - acc: 0.8040 - val_loss: 0.5177 - val_acc: 0.7545\n",
            "Epoch 631/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4121 - acc: 0.8026 - val_loss: 0.5498 - val_acc: 0.7174\n",
            "Epoch 632/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4059 - acc: 0.8112 - val_loss: 0.5414 - val_acc: 0.7613\n",
            "Epoch 633/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4069 - acc: 0.8102 - val_loss: 0.5062 - val_acc: 0.7558\n",
            "Epoch 634/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4021 - acc: 0.8122 - val_loss: 0.5999 - val_acc: 0.7106\n",
            "Epoch 635/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4068 - acc: 0.8119 - val_loss: 0.5168 - val_acc: 0.7503\n",
            "Epoch 636/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4040 - acc: 0.8088 - val_loss: 0.5035 - val_acc: 0.7545\n",
            "Epoch 637/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4084 - acc: 0.8091 - val_loss: 0.5282 - val_acc: 0.7449\n",
            "Epoch 638/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4199 - acc: 0.7971 - val_loss: 0.5007 - val_acc: 0.7750\n",
            "Epoch 639/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4003 - acc: 0.8143 - val_loss: 0.5086 - val_acc: 0.7476\n",
            "Epoch 640/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4002 - acc: 0.8136 - val_loss: 0.5270 - val_acc: 0.7613\n",
            "Epoch 641/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4070 - acc: 0.8057 - val_loss: 0.5240 - val_acc: 0.7613\n",
            "Epoch 642/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4032 - acc: 0.8133 - val_loss: 0.5126 - val_acc: 0.7558\n",
            "Epoch 643/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3951 - acc: 0.8153 - val_loss: 0.5342 - val_acc: 0.7449\n",
            "Epoch 644/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4179 - acc: 0.8033 - val_loss: 0.5112 - val_acc: 0.7545\n",
            "Epoch 645/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3968 - acc: 0.8146 - val_loss: 0.5282 - val_acc: 0.7407\n",
            "Epoch 646/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4050 - acc: 0.8067 - val_loss: 0.5441 - val_acc: 0.7202\n",
            "Epoch 647/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.4022 - acc: 0.8115 - val_loss: 0.5082 - val_acc: 0.7558\n",
            "Epoch 648/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4039 - acc: 0.8054 - val_loss: 0.5249 - val_acc: 0.7435\n",
            "Epoch 649/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4022 - acc: 0.8153 - val_loss: 0.5035 - val_acc: 0.7531\n",
            "Epoch 650/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3966 - acc: 0.8167 - val_loss: 0.5560 - val_acc: 0.7174\n",
            "Epoch 651/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4132 - acc: 0.8060 - val_loss: 0.6548 - val_acc: 0.7160\n",
            "Epoch 652/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4013 - acc: 0.8163 - val_loss: 0.5300 - val_acc: 0.7298\n",
            "Epoch 653/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3911 - acc: 0.8215 - val_loss: 0.5939 - val_acc: 0.6996\n",
            "Epoch 654/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4081 - acc: 0.8040 - val_loss: 0.4995 - val_acc: 0.7613\n",
            "Epoch 655/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3887 - acc: 0.8205 - val_loss: 0.5209 - val_acc: 0.7517\n",
            "Epoch 656/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4121 - acc: 0.8033 - val_loss: 0.4997 - val_acc: 0.7641\n",
            "Epoch 657/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4106 - acc: 0.8115 - val_loss: 0.5178 - val_acc: 0.7586\n",
            "Epoch 658/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3957 - acc: 0.8157 - val_loss: 0.5066 - val_acc: 0.7613\n",
            "Epoch 659/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3998 - acc: 0.8139 - val_loss: 0.5310 - val_acc: 0.7284\n",
            "Epoch 660/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.3894 - acc: 0.8187 - val_loss: 0.5192 - val_acc: 0.7449\n",
            "Epoch 661/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4161 - acc: 0.8030 - val_loss: 0.5458 - val_acc: 0.7229\n",
            "Epoch 662/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3894 - acc: 0.8191 - val_loss: 0.5125 - val_acc: 0.7558\n",
            "Epoch 663/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4086 - acc: 0.8091 - val_loss: 0.5038 - val_acc: 0.7586\n",
            "Epoch 664/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3957 - acc: 0.8163 - val_loss: 0.5157 - val_acc: 0.7545\n",
            "Epoch 665/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3977 - acc: 0.8139 - val_loss: 0.6211 - val_acc: 0.7064\n",
            "Epoch 666/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3948 - acc: 0.8201 - val_loss: 0.6484 - val_acc: 0.7051\n",
            "Epoch 667/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4093 - acc: 0.8067 - val_loss: 0.5238 - val_acc: 0.7366\n",
            "Epoch 668/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3945 - acc: 0.8143 - val_loss: 0.4984 - val_acc: 0.7668\n",
            "Epoch 669/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3902 - acc: 0.8215 - val_loss: 0.5143 - val_acc: 0.7462\n",
            "Epoch 670/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4113 - acc: 0.8054 - val_loss: 0.5015 - val_acc: 0.7641\n",
            "Epoch 671/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3996 - acc: 0.8084 - val_loss: 0.5176 - val_acc: 0.7366\n",
            "Epoch 672/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3986 - acc: 0.8098 - val_loss: 0.5045 - val_acc: 0.7572\n",
            "Epoch 673/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3990 - acc: 0.8122 - val_loss: 0.5534 - val_acc: 0.7188\n",
            "Epoch 674/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4048 - acc: 0.8163 - val_loss: 0.5241 - val_acc: 0.7545\n",
            "Epoch 675/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3934 - acc: 0.8157 - val_loss: 0.5136 - val_acc: 0.7517\n",
            "Epoch 676/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3912 - acc: 0.8160 - val_loss: 0.5031 - val_acc: 0.7586\n",
            "Epoch 677/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4007 - acc: 0.8122 - val_loss: 0.5078 - val_acc: 0.7641\n",
            "Epoch 678/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3880 - acc: 0.8136 - val_loss: 0.6301 - val_acc: 0.7298\n",
            "Epoch 679/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4044 - acc: 0.8091 - val_loss: 0.5166 - val_acc: 0.7558\n",
            "Epoch 680/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3902 - acc: 0.8167 - val_loss: 0.5362 - val_acc: 0.7449\n",
            "Epoch 681/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4033 - acc: 0.8078 - val_loss: 0.5345 - val_acc: 0.7325\n",
            "Epoch 682/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3916 - acc: 0.8198 - val_loss: 0.5070 - val_acc: 0.7627\n",
            "Epoch 683/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3969 - acc: 0.8133 - val_loss: 0.5049 - val_acc: 0.7613\n",
            "Epoch 684/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3930 - acc: 0.8160 - val_loss: 0.5170 - val_acc: 0.7545\n",
            "Epoch 685/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3874 - acc: 0.8177 - val_loss: 0.5167 - val_acc: 0.7558\n",
            "Epoch 686/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3986 - acc: 0.8146 - val_loss: 0.6309 - val_acc: 0.7298\n",
            "Epoch 687/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.4052 - acc: 0.8157 - val_loss: 0.5193 - val_acc: 0.7531\n",
            "Epoch 688/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3857 - acc: 0.8157 - val_loss: 0.5328 - val_acc: 0.7339\n",
            "Epoch 689/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3963 - acc: 0.8084 - val_loss: 0.5353 - val_acc: 0.7298\n",
            "Epoch 690/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3990 - acc: 0.8043 - val_loss: 0.5336 - val_acc: 0.7462\n",
            "Epoch 691/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3879 - acc: 0.8215 - val_loss: 0.5190 - val_acc: 0.7380\n",
            "Epoch 692/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4040 - acc: 0.8129 - val_loss: 0.5018 - val_acc: 0.7558\n",
            "Epoch 693/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3879 - acc: 0.8215 - val_loss: 0.5380 - val_acc: 0.7435\n",
            "Epoch 694/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3956 - acc: 0.8177 - val_loss: 0.5199 - val_acc: 0.7449\n",
            "Epoch 695/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3870 - acc: 0.8239 - val_loss: 0.5461 - val_acc: 0.7311\n",
            "Epoch 696/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3950 - acc: 0.8105 - val_loss: 0.5276 - val_acc: 0.7380\n",
            "Epoch 697/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3832 - acc: 0.8184 - val_loss: 0.5808 - val_acc: 0.7037\n",
            "Epoch 698/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3925 - acc: 0.8119 - val_loss: 0.7323 - val_acc: 0.7010\n",
            "Epoch 699/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3990 - acc: 0.8102 - val_loss: 0.5409 - val_acc: 0.7462\n",
            "Epoch 700/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3843 - acc: 0.8205 - val_loss: 0.5114 - val_acc: 0.7476\n",
            "Epoch 701/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4084 - acc: 0.8081 - val_loss: 0.5017 - val_acc: 0.7545\n",
            "Epoch 702/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3881 - acc: 0.8187 - val_loss: 0.5291 - val_acc: 0.7476\n",
            "Epoch 703/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3872 - acc: 0.8160 - val_loss: 0.5048 - val_acc: 0.7586\n",
            "Epoch 704/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3926 - acc: 0.8266 - val_loss: 0.5328 - val_acc: 0.7325\n",
            "Epoch 705/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3977 - acc: 0.8102 - val_loss: 0.5087 - val_acc: 0.7517\n",
            "Epoch 706/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3906 - acc: 0.8174 - val_loss: 0.5911 - val_acc: 0.7449\n",
            "Epoch 707/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3971 - acc: 0.8260 - val_loss: 0.5123 - val_acc: 0.7531\n",
            "Epoch 708/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3886 - acc: 0.8205 - val_loss: 0.5054 - val_acc: 0.7558\n",
            "Epoch 709/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3852 - acc: 0.8153 - val_loss: 0.5926 - val_acc: 0.7202\n",
            "Epoch 710/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3964 - acc: 0.8184 - val_loss: 0.5176 - val_acc: 0.7476\n",
            "Epoch 711/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3893 - acc: 0.8187 - val_loss: 0.5345 - val_acc: 0.7298\n",
            "Epoch 712/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3952 - acc: 0.8201 - val_loss: 0.6302 - val_acc: 0.7380\n",
            "Epoch 713/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3969 - acc: 0.8071 - val_loss: 0.5164 - val_acc: 0.7490\n",
            "Epoch 714/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3843 - acc: 0.8222 - val_loss: 0.5038 - val_acc: 0.7572\n",
            "Epoch 715/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3879 - acc: 0.8146 - val_loss: 0.5075 - val_acc: 0.7613\n",
            "Epoch 716/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4119 - acc: 0.8098 - val_loss: 0.5293 - val_acc: 0.7490\n",
            "Epoch 717/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3869 - acc: 0.8229 - val_loss: 0.5384 - val_acc: 0.7394\n",
            "Epoch 718/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3833 - acc: 0.8246 - val_loss: 0.5246 - val_acc: 0.7490\n",
            "Epoch 719/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3979 - acc: 0.8177 - val_loss: 0.5095 - val_acc: 0.7558\n",
            "Epoch 720/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3871 - acc: 0.8136 - val_loss: 0.5035 - val_acc: 0.7558\n",
            "Epoch 721/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4122 - acc: 0.8126 - val_loss: 0.4996 - val_acc: 0.7654\n",
            "Epoch 722/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3781 - acc: 0.8297 - val_loss: 0.5452 - val_acc: 0.7270\n",
            "Epoch 723/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3797 - acc: 0.8232 - val_loss: 0.5796 - val_acc: 0.7064\n",
            "Epoch 724/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3899 - acc: 0.8191 - val_loss: 0.5180 - val_acc: 0.7476\n",
            "Epoch 725/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3786 - acc: 0.8253 - val_loss: 0.5306 - val_acc: 0.7490\n",
            "Epoch 726/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.4112 - acc: 0.8050 - val_loss: 0.5034 - val_acc: 0.7599\n",
            "Epoch 727/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3790 - acc: 0.8253 - val_loss: 0.5209 - val_acc: 0.7435\n",
            "Epoch 728/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3891 - acc: 0.8187 - val_loss: 0.5118 - val_acc: 0.7572\n",
            "Epoch 729/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3873 - acc: 0.8146 - val_loss: 0.5442 - val_acc: 0.7298\n",
            "Epoch 730/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4133 - acc: 0.8177 - val_loss: 0.5229 - val_acc: 0.7503\n",
            "Epoch 731/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3750 - acc: 0.8297 - val_loss: 0.5161 - val_acc: 0.7476\n",
            "Epoch 732/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.4042 - acc: 0.8064 - val_loss: 0.5651 - val_acc: 0.7174\n",
            "Epoch 733/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3774 - acc: 0.8273 - val_loss: 0.5122 - val_acc: 0.7558\n",
            "Epoch 734/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3888 - acc: 0.8194 - val_loss: 0.5041 - val_acc: 0.7627\n",
            "Epoch 735/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3822 - acc: 0.8239 - val_loss: 0.5109 - val_acc: 0.7572\n",
            "Epoch 736/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3881 - acc: 0.8119 - val_loss: 0.5629 - val_acc: 0.7160\n",
            "Epoch 737/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3857 - acc: 0.8225 - val_loss: 0.5035 - val_acc: 0.7572\n",
            "Epoch 738/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3943 - acc: 0.8146 - val_loss: 0.5290 - val_acc: 0.7380\n",
            "Epoch 739/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3752 - acc: 0.8256 - val_loss: 0.5041 - val_acc: 0.7545\n",
            "Epoch 740/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3895 - acc: 0.8191 - val_loss: 0.5221 - val_acc: 0.7449\n",
            "Epoch 741/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3882 - acc: 0.8163 - val_loss: 0.5397 - val_acc: 0.7503\n",
            "Epoch 742/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3749 - acc: 0.8290 - val_loss: 0.5057 - val_acc: 0.7613\n",
            "Epoch 743/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3978 - acc: 0.8150 - val_loss: 0.5061 - val_acc: 0.7572\n",
            "Epoch 744/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3854 - acc: 0.8167 - val_loss: 0.5441 - val_acc: 0.7435\n",
            "Epoch 745/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3777 - acc: 0.8277 - val_loss: 0.5153 - val_acc: 0.7531\n",
            "Epoch 746/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3947 - acc: 0.8170 - val_loss: 0.5036 - val_acc: 0.7558\n",
            "Epoch 747/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3778 - acc: 0.8211 - val_loss: 0.5261 - val_acc: 0.7421\n",
            "Epoch 748/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3798 - acc: 0.8133 - val_loss: 0.5276 - val_acc: 0.7531\n",
            "Epoch 749/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3994 - acc: 0.8184 - val_loss: 0.5302 - val_acc: 0.7407\n",
            "Epoch 750/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3743 - acc: 0.8287 - val_loss: 0.5467 - val_acc: 0.7311\n",
            "Epoch 751/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3827 - acc: 0.8201 - val_loss: 0.5181 - val_acc: 0.7503\n",
            "Epoch 752/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3934 - acc: 0.8170 - val_loss: 0.5247 - val_acc: 0.7490\n",
            "Epoch 753/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.3736 - acc: 0.8297 - val_loss: 0.5147 - val_acc: 0.7599\n",
            "Epoch 754/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.4012 - acc: 0.8170 - val_loss: 0.5171 - val_acc: 0.7476\n",
            "Epoch 755/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3737 - acc: 0.8311 - val_loss: 0.5300 - val_acc: 0.7435\n",
            "Epoch 756/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3806 - acc: 0.8260 - val_loss: 0.5278 - val_acc: 0.7462\n",
            "Epoch 757/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3877 - acc: 0.8163 - val_loss: 0.5152 - val_acc: 0.7572\n",
            "Epoch 758/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3867 - acc: 0.8266 - val_loss: 0.5058 - val_acc: 0.7531\n",
            "Epoch 759/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3951 - acc: 0.8108 - val_loss: 0.5149 - val_acc: 0.7490\n",
            "Epoch 760/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3724 - acc: 0.8301 - val_loss: 0.5040 - val_acc: 0.7654\n",
            "Epoch 761/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3805 - acc: 0.8242 - val_loss: 0.5356 - val_acc: 0.7503\n",
            "Epoch 762/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3898 - acc: 0.8177 - val_loss: 0.5575 - val_acc: 0.7613\n",
            "Epoch 763/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3829 - acc: 0.8187 - val_loss: 0.5126 - val_acc: 0.7558\n",
            "Epoch 764/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3997 - acc: 0.8215 - val_loss: 0.5356 - val_acc: 0.7353\n",
            "Epoch 765/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3721 - acc: 0.8328 - val_loss: 0.5041 - val_acc: 0.7613\n",
            "Epoch 766/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3734 - acc: 0.8270 - val_loss: 0.5116 - val_acc: 0.7572\n",
            "Epoch 767/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3775 - acc: 0.8211 - val_loss: 0.5846 - val_acc: 0.7449\n",
            "Epoch 768/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3874 - acc: 0.8208 - val_loss: 0.5577 - val_acc: 0.7284\n",
            "Epoch 769/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3788 - acc: 0.8232 - val_loss: 0.5153 - val_acc: 0.7572\n",
            "Epoch 770/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3733 - acc: 0.8256 - val_loss: 0.5730 - val_acc: 0.7366\n",
            "Epoch 771/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.4103 - acc: 0.8150 - val_loss: 0.5100 - val_acc: 0.7599\n",
            "Epoch 772/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3669 - acc: 0.8383 - val_loss: 0.5111 - val_acc: 0.7599\n",
            "Epoch 773/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3761 - acc: 0.8235 - val_loss: 0.5663 - val_acc: 0.7257\n",
            "Epoch 774/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3735 - acc: 0.8308 - val_loss: 0.5594 - val_acc: 0.7407\n",
            "Epoch 775/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3940 - acc: 0.8194 - val_loss: 0.5955 - val_acc: 0.7078\n",
            "Epoch 776/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3720 - acc: 0.8328 - val_loss: 0.5094 - val_acc: 0.7627\n",
            "Epoch 777/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3914 - acc: 0.8191 - val_loss: 0.5124 - val_acc: 0.7586\n",
            "Epoch 778/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3804 - acc: 0.8260 - val_loss: 0.5874 - val_acc: 0.7257\n",
            "Epoch 779/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3805 - acc: 0.8301 - val_loss: 0.6129 - val_acc: 0.7078\n",
            "Epoch 780/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3860 - acc: 0.8249 - val_loss: 0.5117 - val_acc: 0.7531\n",
            "Epoch 781/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3770 - acc: 0.8222 - val_loss: 0.5372 - val_acc: 0.7394\n",
            "Epoch 782/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3750 - acc: 0.8328 - val_loss: 0.5301 - val_acc: 0.7449\n",
            "Epoch 783/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3862 - acc: 0.8211 - val_loss: 0.5097 - val_acc: 0.7517\n",
            "Epoch 784/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3800 - acc: 0.8273 - val_loss: 0.6311 - val_acc: 0.7394\n",
            "Epoch 785/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3734 - acc: 0.8273 - val_loss: 0.5877 - val_acc: 0.7147\n",
            "Epoch 786/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3733 - acc: 0.8297 - val_loss: 0.5867 - val_acc: 0.7572\n",
            "Epoch 787/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3681 - acc: 0.8304 - val_loss: 0.5840 - val_acc: 0.7311\n",
            "Epoch 788/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3840 - acc: 0.8287 - val_loss: 0.5124 - val_acc: 0.7586\n",
            "Epoch 789/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3825 - acc: 0.8218 - val_loss: 0.5333 - val_acc: 0.7380\n",
            "Epoch 790/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3692 - acc: 0.8277 - val_loss: 0.5098 - val_acc: 0.7531\n",
            "Epoch 791/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3788 - acc: 0.8277 - val_loss: 0.5060 - val_acc: 0.7668\n",
            "Epoch 792/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3752 - acc: 0.8311 - val_loss: 0.5548 - val_acc: 0.7394\n",
            "Epoch 793/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3741 - acc: 0.8328 - val_loss: 0.5094 - val_acc: 0.7599\n",
            "Epoch 794/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3844 - acc: 0.8235 - val_loss: 0.6378 - val_acc: 0.7366\n",
            "Epoch 795/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3726 - acc: 0.8304 - val_loss: 0.5046 - val_acc: 0.7654\n",
            "Epoch 796/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3706 - acc: 0.8229 - val_loss: 0.5239 - val_acc: 0.7558\n",
            "Epoch 797/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3749 - acc: 0.8232 - val_loss: 0.6362 - val_acc: 0.7380\n",
            "Epoch 798/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3786 - acc: 0.8349 - val_loss: 0.5574 - val_acc: 0.7284\n",
            "Epoch 799/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3719 - acc: 0.8249 - val_loss: 0.5029 - val_acc: 0.7682\n",
            "Epoch 800/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3761 - acc: 0.8304 - val_loss: 0.5347 - val_acc: 0.7421\n",
            "Epoch 801/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3725 - acc: 0.8266 - val_loss: 0.5113 - val_acc: 0.7572\n",
            "Epoch 802/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3643 - acc: 0.8338 - val_loss: 0.5139 - val_acc: 0.7586\n",
            "Epoch 803/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.4067 - acc: 0.8198 - val_loss: 0.5008 - val_acc: 0.7641\n",
            "Epoch 804/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3618 - acc: 0.8373 - val_loss: 0.5446 - val_acc: 0.7284\n",
            "Epoch 805/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3742 - acc: 0.8232 - val_loss: 0.5643 - val_acc: 0.7257\n",
            "Epoch 806/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3698 - acc: 0.8349 - val_loss: 0.5083 - val_acc: 0.7654\n",
            "Epoch 807/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3725 - acc: 0.8342 - val_loss: 0.5237 - val_acc: 0.7490\n",
            "Epoch 808/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3684 - acc: 0.8328 - val_loss: 0.5658 - val_acc: 0.7449\n",
            "Epoch 809/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3710 - acc: 0.8304 - val_loss: 0.5605 - val_acc: 0.7229\n",
            "Epoch 810/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3624 - acc: 0.8328 - val_loss: 0.5244 - val_acc: 0.7627\n",
            "Epoch 811/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3839 - acc: 0.8218 - val_loss: 0.5633 - val_acc: 0.7421\n",
            "Epoch 812/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3790 - acc: 0.8201 - val_loss: 0.5137 - val_acc: 0.7586\n",
            "Epoch 813/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3615 - acc: 0.8352 - val_loss: 0.5287 - val_acc: 0.7462\n",
            "Epoch 814/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3703 - acc: 0.8242 - val_loss: 0.6034 - val_acc: 0.7531\n",
            "Epoch 815/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3875 - acc: 0.8314 - val_loss: 0.5543 - val_acc: 0.7380\n",
            "Epoch 816/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3728 - acc: 0.8277 - val_loss: 0.5439 - val_acc: 0.7353\n",
            "Epoch 817/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3686 - acc: 0.8263 - val_loss: 0.6831 - val_acc: 0.7174\n",
            "Epoch 818/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3681 - acc: 0.8349 - val_loss: 0.5054 - val_acc: 0.7654\n",
            "Epoch 819/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3692 - acc: 0.8294 - val_loss: 0.5402 - val_acc: 0.7490\n",
            "Epoch 820/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3687 - acc: 0.8287 - val_loss: 0.5070 - val_acc: 0.7668\n",
            "Epoch 821/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3680 - acc: 0.8277 - val_loss: 0.5122 - val_acc: 0.7627\n",
            "Epoch 822/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3745 - acc: 0.8266 - val_loss: 0.5194 - val_acc: 0.7627\n",
            "Epoch 823/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3671 - acc: 0.8321 - val_loss: 0.5622 - val_acc: 0.7394\n",
            "Epoch 824/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3781 - acc: 0.8256 - val_loss: 0.5171 - val_acc: 0.7421\n",
            "Epoch 825/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3651 - acc: 0.8304 - val_loss: 0.6529 - val_acc: 0.7380\n",
            "Epoch 826/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3898 - acc: 0.8246 - val_loss: 0.5095 - val_acc: 0.7627\n",
            "Epoch 827/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3643 - acc: 0.8356 - val_loss: 0.5014 - val_acc: 0.7641\n",
            "Epoch 828/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3771 - acc: 0.8284 - val_loss: 0.5080 - val_acc: 0.7641\n",
            "Epoch 829/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3588 - acc: 0.8349 - val_loss: 0.5085 - val_acc: 0.7531\n",
            "Epoch 830/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3688 - acc: 0.8273 - val_loss: 0.5074 - val_acc: 0.7709\n",
            "Epoch 831/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3629 - acc: 0.8366 - val_loss: 0.5785 - val_acc: 0.7257\n",
            "Epoch 832/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3736 - acc: 0.8225 - val_loss: 0.5036 - val_acc: 0.7654\n",
            "Epoch 833/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3859 - acc: 0.8235 - val_loss: 0.5122 - val_acc: 0.7531\n",
            "Epoch 834/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3622 - acc: 0.8431 - val_loss: 0.5063 - val_acc: 0.7599\n",
            "Epoch 835/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3596 - acc: 0.8332 - val_loss: 0.5712 - val_acc: 0.7421\n",
            "Epoch 836/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3804 - acc: 0.8304 - val_loss: 0.5325 - val_acc: 0.7421\n",
            "Epoch 837/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3615 - acc: 0.8356 - val_loss: 0.5257 - val_acc: 0.7572\n",
            "Epoch 838/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3813 - acc: 0.8194 - val_loss: 0.4948 - val_acc: 0.7627\n",
            "Epoch 839/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3583 - acc: 0.8314 - val_loss: 0.5000 - val_acc: 0.7723\n",
            "Epoch 840/1000\n",
            "2913/2913 [==============================] - 0s 90us/step - loss: 0.3740 - acc: 0.8314 - val_loss: 0.5200 - val_acc: 0.7668\n",
            "Epoch 841/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3581 - acc: 0.8380 - val_loss: 0.4999 - val_acc: 0.7613\n",
            "Epoch 842/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3749 - acc: 0.8277 - val_loss: 0.5694 - val_acc: 0.7462\n",
            "Epoch 843/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3588 - acc: 0.8301 - val_loss: 0.5134 - val_acc: 0.7503\n",
            "Epoch 844/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3544 - acc: 0.8407 - val_loss: 0.5112 - val_acc: 0.7586\n",
            "Epoch 845/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3757 - acc: 0.8266 - val_loss: 0.5384 - val_acc: 0.7366\n",
            "Epoch 846/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3645 - acc: 0.8332 - val_loss: 0.5667 - val_acc: 0.7284\n",
            "Epoch 847/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3655 - acc: 0.8308 - val_loss: 0.5117 - val_acc: 0.7545\n",
            "Epoch 848/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3719 - acc: 0.8308 - val_loss: 0.5488 - val_acc: 0.7449\n",
            "Epoch 849/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3632 - acc: 0.8328 - val_loss: 0.5206 - val_acc: 0.7517\n",
            "Epoch 850/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3588 - acc: 0.8359 - val_loss: 0.5010 - val_acc: 0.7599\n",
            "Epoch 851/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3683 - acc: 0.8363 - val_loss: 0.5210 - val_acc: 0.7531\n",
            "Epoch 852/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3627 - acc: 0.8345 - val_loss: 0.5487 - val_acc: 0.7558\n",
            "Epoch 853/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3756 - acc: 0.8318 - val_loss: 0.4985 - val_acc: 0.7682\n",
            "Epoch 854/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3949 - acc: 0.8208 - val_loss: 0.5125 - val_acc: 0.7586\n",
            "Epoch 855/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3527 - acc: 0.8431 - val_loss: 0.5013 - val_acc: 0.7627\n",
            "Epoch 856/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3685 - acc: 0.8290 - val_loss: 0.5028 - val_acc: 0.7668\n",
            "Epoch 857/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3538 - acc: 0.8390 - val_loss: 0.5010 - val_acc: 0.7737\n",
            "Epoch 858/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3641 - acc: 0.8328 - val_loss: 0.5090 - val_acc: 0.7627\n",
            "Epoch 859/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3575 - acc: 0.8369 - val_loss: 0.5009 - val_acc: 0.7599\n",
            "Epoch 860/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3520 - acc: 0.8397 - val_loss: 0.5605 - val_acc: 0.7407\n",
            "Epoch 861/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3771 - acc: 0.8205 - val_loss: 0.5235 - val_acc: 0.7407\n",
            "Epoch 862/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3521 - acc: 0.8366 - val_loss: 0.5408 - val_acc: 0.7380\n",
            "Epoch 863/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3666 - acc: 0.8304 - val_loss: 0.5612 - val_acc: 0.7284\n",
            "Epoch 864/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3764 - acc: 0.8349 - val_loss: 0.5139 - val_acc: 0.7394\n",
            "Epoch 865/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3561 - acc: 0.8373 - val_loss: 0.5427 - val_acc: 0.7654\n",
            "Epoch 866/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3797 - acc: 0.8359 - val_loss: 0.5342 - val_acc: 0.7599\n",
            "Epoch 867/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3619 - acc: 0.8294 - val_loss: 0.5279 - val_acc: 0.7531\n",
            "Epoch 868/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3574 - acc: 0.8356 - val_loss: 0.4971 - val_acc: 0.7682\n",
            "Epoch 869/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3604 - acc: 0.8321 - val_loss: 0.4989 - val_acc: 0.7695\n",
            "Epoch 870/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3663 - acc: 0.8380 - val_loss: 0.5365 - val_acc: 0.7366\n",
            "Epoch 871/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3818 - acc: 0.8242 - val_loss: 0.4998 - val_acc: 0.7668\n",
            "Epoch 872/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3510 - acc: 0.8414 - val_loss: 0.5334 - val_acc: 0.7517\n",
            "Epoch 873/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3570 - acc: 0.8369 - val_loss: 0.5249 - val_acc: 0.7407\n",
            "Epoch 874/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3655 - acc: 0.8325 - val_loss: 0.5166 - val_acc: 0.7449\n",
            "Epoch 875/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3530 - acc: 0.8435 - val_loss: 0.5082 - val_acc: 0.7627\n",
            "Epoch 876/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3607 - acc: 0.8342 - val_loss: 0.5207 - val_acc: 0.7558\n",
            "Epoch 877/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3712 - acc: 0.8363 - val_loss: 0.5663 - val_acc: 0.7517\n",
            "Epoch 878/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3532 - acc: 0.8404 - val_loss: 0.5798 - val_acc: 0.7270\n",
            "Epoch 879/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3646 - acc: 0.8428 - val_loss: 0.5038 - val_acc: 0.7695\n",
            "Epoch 880/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3517 - acc: 0.8441 - val_loss: 0.5012 - val_acc: 0.7695\n",
            "Epoch 881/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3753 - acc: 0.8273 - val_loss: 0.6205 - val_acc: 0.7421\n",
            "Epoch 882/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3587 - acc: 0.8387 - val_loss: 0.5367 - val_acc: 0.7339\n",
            "Epoch 883/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3512 - acc: 0.8345 - val_loss: 0.5053 - val_acc: 0.7668\n",
            "Epoch 884/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3548 - acc: 0.8411 - val_loss: 0.5352 - val_acc: 0.7545\n",
            "Epoch 885/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3634 - acc: 0.8390 - val_loss: 0.5203 - val_acc: 0.7599\n",
            "Epoch 886/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3502 - acc: 0.8445 - val_loss: 0.5550 - val_acc: 0.7517\n",
            "Epoch 887/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3571 - acc: 0.8421 - val_loss: 0.5250 - val_acc: 0.7558\n",
            "Epoch 888/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3516 - acc: 0.8465 - val_loss: 0.5058 - val_acc: 0.7695\n",
            "Epoch 889/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3647 - acc: 0.8321 - val_loss: 0.5034 - val_acc: 0.7709\n",
            "Epoch 890/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3601 - acc: 0.8345 - val_loss: 0.5046 - val_acc: 0.7613\n",
            "Epoch 891/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3514 - acc: 0.8404 - val_loss: 0.5187 - val_acc: 0.7503\n",
            "Epoch 892/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3750 - acc: 0.8266 - val_loss: 0.5199 - val_acc: 0.7517\n",
            "Epoch 893/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3568 - acc: 0.8345 - val_loss: 0.5067 - val_acc: 0.7668\n",
            "Epoch 894/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3590 - acc: 0.8352 - val_loss: 0.5086 - val_acc: 0.7709\n",
            "Epoch 895/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3535 - acc: 0.8459 - val_loss: 0.5222 - val_acc: 0.7503\n",
            "Epoch 896/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3501 - acc: 0.8411 - val_loss: 0.5072 - val_acc: 0.7668\n",
            "Epoch 897/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3882 - acc: 0.8284 - val_loss: 0.5075 - val_acc: 0.7695\n",
            "Epoch 898/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3461 - acc: 0.8445 - val_loss: 0.5120 - val_acc: 0.7545\n",
            "Epoch 899/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3548 - acc: 0.8421 - val_loss: 0.5259 - val_acc: 0.7599\n",
            "Epoch 900/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3504 - acc: 0.8369 - val_loss: 0.5273 - val_acc: 0.7545\n",
            "Epoch 901/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3788 - acc: 0.8338 - val_loss: 0.5091 - val_acc: 0.7709\n",
            "Epoch 902/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3484 - acc: 0.8383 - val_loss: 0.5176 - val_acc: 0.7517\n",
            "Epoch 903/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3473 - acc: 0.8493 - val_loss: 0.5181 - val_acc: 0.7572\n",
            "Epoch 904/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3764 - acc: 0.8342 - val_loss: 0.5026 - val_acc: 0.7613\n",
            "Epoch 905/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3494 - acc: 0.8431 - val_loss: 0.5219 - val_acc: 0.7613\n",
            "Epoch 906/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3716 - acc: 0.8270 - val_loss: 0.5099 - val_acc: 0.7599\n",
            "Epoch 907/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3499 - acc: 0.8407 - val_loss: 0.5508 - val_acc: 0.7572\n",
            "Epoch 908/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3520 - acc: 0.8356 - val_loss: 0.5468 - val_acc: 0.7366\n",
            "Epoch 909/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3502 - acc: 0.8411 - val_loss: 0.5127 - val_acc: 0.7545\n",
            "Epoch 910/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3780 - acc: 0.8270 - val_loss: 0.5046 - val_acc: 0.7723\n",
            "Epoch 911/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3430 - acc: 0.8465 - val_loss: 0.5044 - val_acc: 0.7723\n",
            "Epoch 912/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3559 - acc: 0.8380 - val_loss: 0.5059 - val_acc: 0.7654\n",
            "Epoch 913/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3598 - acc: 0.8411 - val_loss: 0.5291 - val_acc: 0.7613\n",
            "Epoch 914/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3486 - acc: 0.8465 - val_loss: 0.5619 - val_acc: 0.7394\n",
            "Epoch 915/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3516 - acc: 0.8421 - val_loss: 0.5121 - val_acc: 0.7641\n",
            "Epoch 916/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3626 - acc: 0.8376 - val_loss: 0.5222 - val_acc: 0.7558\n",
            "Epoch 917/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3560 - acc: 0.8359 - val_loss: 0.5248 - val_acc: 0.7531\n",
            "Epoch 918/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3462 - acc: 0.8465 - val_loss: 0.5364 - val_acc: 0.7394\n",
            "Epoch 919/1000\n",
            "2913/2913 [==============================] - 0s 87us/step - loss: 0.3557 - acc: 0.8390 - val_loss: 0.5177 - val_acc: 0.7572\n",
            "Epoch 920/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.3580 - acc: 0.8387 - val_loss: 0.5314 - val_acc: 0.7517\n",
            "Epoch 921/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3560 - acc: 0.8390 - val_loss: 0.5069 - val_acc: 0.7641\n",
            "Epoch 922/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3492 - acc: 0.8448 - val_loss: 0.5202 - val_acc: 0.7517\n",
            "Epoch 923/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3505 - acc: 0.8435 - val_loss: 0.5139 - val_acc: 0.7599\n",
            "Epoch 924/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3640 - acc: 0.8400 - val_loss: 0.5091 - val_acc: 0.7668\n",
            "Epoch 925/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3452 - acc: 0.8448 - val_loss: 0.5065 - val_acc: 0.7709\n",
            "Epoch 926/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3683 - acc: 0.8383 - val_loss: 0.5300 - val_acc: 0.7435\n",
            "Epoch 927/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3458 - acc: 0.8448 - val_loss: 0.5086 - val_acc: 0.7545\n",
            "Epoch 928/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3583 - acc: 0.8294 - val_loss: 0.5138 - val_acc: 0.7613\n",
            "Epoch 929/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3432 - acc: 0.8438 - val_loss: 0.5050 - val_acc: 0.7599\n",
            "Epoch 930/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3629 - acc: 0.8366 - val_loss: 0.7370 - val_acc: 0.6941\n",
            "Epoch 931/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3595 - acc: 0.8376 - val_loss: 0.5064 - val_acc: 0.7668\n",
            "Epoch 932/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3410 - acc: 0.8483 - val_loss: 0.5042 - val_acc: 0.7627\n",
            "Epoch 933/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3515 - acc: 0.8417 - val_loss: 0.5217 - val_acc: 0.7599\n",
            "Epoch 934/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3466 - acc: 0.8469 - val_loss: 0.5486 - val_acc: 0.7366\n",
            "Epoch 935/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3414 - acc: 0.8452 - val_loss: 0.6008 - val_acc: 0.7270\n",
            "Epoch 936/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3588 - acc: 0.8325 - val_loss: 0.5331 - val_acc: 0.7545\n",
            "Epoch 937/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3418 - acc: 0.8486 - val_loss: 0.5061 - val_acc: 0.7709\n",
            "Epoch 938/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3586 - acc: 0.8400 - val_loss: 0.5099 - val_acc: 0.7682\n",
            "Epoch 939/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3574 - acc: 0.8376 - val_loss: 0.5271 - val_acc: 0.7503\n",
            "Epoch 940/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3460 - acc: 0.8431 - val_loss: 0.5274 - val_acc: 0.7503\n",
            "Epoch 941/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3582 - acc: 0.8321 - val_loss: 0.5608 - val_acc: 0.7586\n",
            "Epoch 942/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3448 - acc: 0.8520 - val_loss: 0.5376 - val_acc: 0.7435\n",
            "Epoch 943/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3627 - acc: 0.8373 - val_loss: 0.5219 - val_acc: 0.7545\n",
            "Epoch 944/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3465 - acc: 0.8428 - val_loss: 0.5108 - val_acc: 0.7709\n",
            "Epoch 945/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3545 - acc: 0.8338 - val_loss: 0.5082 - val_acc: 0.7723\n",
            "Epoch 946/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3595 - acc: 0.8363 - val_loss: 0.5120 - val_acc: 0.7627\n",
            "Epoch 947/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3369 - acc: 0.8490 - val_loss: 0.6058 - val_acc: 0.7517\n",
            "Epoch 948/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3495 - acc: 0.8441 - val_loss: 0.5414 - val_acc: 0.7449\n",
            "Epoch 949/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3656 - acc: 0.8311 - val_loss: 0.5146 - val_acc: 0.7654\n",
            "Epoch 950/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3447 - acc: 0.8469 - val_loss: 0.5126 - val_acc: 0.7586\n",
            "Epoch 951/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3524 - acc: 0.8435 - val_loss: 0.5240 - val_acc: 0.7586\n",
            "Epoch 952/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3437 - acc: 0.8428 - val_loss: 0.5370 - val_acc: 0.7627\n",
            "Epoch 953/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3504 - acc: 0.8431 - val_loss: 0.7314 - val_acc: 0.7311\n",
            "Epoch 954/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.3667 - acc: 0.8438 - val_loss: 0.5119 - val_acc: 0.7668\n",
            "Epoch 955/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3420 - acc: 0.8496 - val_loss: 0.5296 - val_acc: 0.7531\n",
            "Epoch 956/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3549 - acc: 0.8352 - val_loss: 0.5270 - val_acc: 0.7558\n",
            "Epoch 957/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3391 - acc: 0.8472 - val_loss: 0.5048 - val_acc: 0.7695\n",
            "Epoch 958/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3549 - acc: 0.8421 - val_loss: 0.5071 - val_acc: 0.7709\n",
            "Epoch 959/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3397 - acc: 0.8459 - val_loss: 0.5530 - val_acc: 0.7325\n",
            "Epoch 960/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3426 - acc: 0.8459 - val_loss: 0.5128 - val_acc: 0.7737\n",
            "Epoch 961/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3710 - acc: 0.8373 - val_loss: 0.5129 - val_acc: 0.7723\n",
            "Epoch 962/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3369 - acc: 0.8462 - val_loss: 0.5447 - val_acc: 0.7572\n",
            "Epoch 963/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3417 - acc: 0.8441 - val_loss: 0.5721 - val_acc: 0.7503\n",
            "Epoch 964/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3785 - acc: 0.8287 - val_loss: 0.5269 - val_acc: 0.7545\n",
            "Epoch 965/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3332 - acc: 0.8483 - val_loss: 0.5447 - val_acc: 0.7380\n",
            "Epoch 966/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3371 - acc: 0.8483 - val_loss: 0.5135 - val_acc: 0.7723\n",
            "Epoch 967/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3480 - acc: 0.8369 - val_loss: 0.5376 - val_acc: 0.7545\n",
            "Epoch 968/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3459 - acc: 0.8435 - val_loss: 0.6920 - val_acc: 0.7394\n",
            "Epoch 969/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3509 - acc: 0.8459 - val_loss: 0.5185 - val_acc: 0.7627\n",
            "Epoch 970/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3343 - acc: 0.8510 - val_loss: 0.6416 - val_acc: 0.7188\n",
            "Epoch 971/1000\n",
            "2913/2913 [==============================] - 0s 80us/step - loss: 0.3566 - acc: 0.8387 - val_loss: 0.5397 - val_acc: 0.7462\n",
            "Epoch 972/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3472 - acc: 0.8411 - val_loss: 0.5281 - val_acc: 0.7531\n",
            "Epoch 973/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3492 - acc: 0.8462 - val_loss: 0.5465 - val_acc: 0.7586\n",
            "Epoch 974/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.3413 - acc: 0.8472 - val_loss: 0.5552 - val_acc: 0.7366\n",
            "Epoch 975/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3486 - acc: 0.8424 - val_loss: 0.5645 - val_acc: 0.7325\n",
            "Epoch 976/1000\n",
            "2913/2913 [==============================] - 0s 84us/step - loss: 0.3424 - acc: 0.8452 - val_loss: 0.5090 - val_acc: 0.7695\n",
            "Epoch 977/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3474 - acc: 0.8469 - val_loss: 0.5318 - val_acc: 0.7572\n",
            "Epoch 978/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3353 - acc: 0.8534 - val_loss: 0.5086 - val_acc: 0.7737\n",
            "Epoch 979/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3502 - acc: 0.8445 - val_loss: 0.6980 - val_acc: 0.7311\n",
            "Epoch 980/1000\n",
            "2913/2913 [==============================] - 0s 89us/step - loss: 0.3544 - acc: 0.8507 - val_loss: 0.5146 - val_acc: 0.7558\n",
            "Epoch 981/1000\n",
            "2913/2913 [==============================] - 0s 85us/step - loss: 0.3398 - acc: 0.8431 - val_loss: 0.5064 - val_acc: 0.7709\n",
            "Epoch 982/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3301 - acc: 0.8565 - val_loss: 0.5054 - val_acc: 0.7627\n",
            "Epoch 983/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3602 - acc: 0.8387 - val_loss: 0.5147 - val_acc: 0.7654\n",
            "Epoch 984/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3373 - acc: 0.8452 - val_loss: 0.5322 - val_acc: 0.7682\n",
            "Epoch 985/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3446 - acc: 0.8424 - val_loss: 0.5813 - val_acc: 0.7339\n",
            "Epoch 986/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3421 - acc: 0.8486 - val_loss: 0.5099 - val_acc: 0.7558\n",
            "Epoch 987/1000\n",
            "2913/2913 [==============================] - 0s 86us/step - loss: 0.3317 - acc: 0.8551 - val_loss: 0.6523 - val_acc: 0.7106\n",
            "Epoch 988/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3502 - acc: 0.8404 - val_loss: 0.5186 - val_acc: 0.7654\n",
            "Epoch 989/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3560 - acc: 0.8383 - val_loss: 0.5074 - val_acc: 0.7695\n",
            "Epoch 990/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3316 - acc: 0.8575 - val_loss: 0.5311 - val_acc: 0.7586\n",
            "Epoch 991/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3378 - acc: 0.8496 - val_loss: 0.5109 - val_acc: 0.7558\n",
            "Epoch 992/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3443 - acc: 0.8417 - val_loss: 0.5035 - val_acc: 0.7668\n",
            "Epoch 993/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3504 - acc: 0.8452 - val_loss: 0.5129 - val_acc: 0.7627\n",
            "Epoch 994/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3347 - acc: 0.8455 - val_loss: 0.5355 - val_acc: 0.7613\n",
            "Epoch 995/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3327 - acc: 0.8507 - val_loss: 0.5327 - val_acc: 0.7545\n",
            "Epoch 996/1000\n",
            "2913/2913 [==============================] - 0s 82us/step - loss: 0.3420 - acc: 0.8455 - val_loss: 0.5041 - val_acc: 0.7723\n",
            "Epoch 997/1000\n",
            "2913/2913 [==============================] - 0s 81us/step - loss: 0.3480 - acc: 0.8486 - val_loss: 0.6082 - val_acc: 0.7490\n",
            "Epoch 998/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3433 - acc: 0.8472 - val_loss: 0.5485 - val_acc: 0.7421\n",
            "Epoch 999/1000\n",
            "2913/2913 [==============================] - 0s 83us/step - loss: 0.3576 - acc: 0.8424 - val_loss: 0.5086 - val_acc: 0.7558\n",
            "Epoch 1000/1000\n",
            "2913/2913 [==============================] - 0s 88us/step - loss: 0.3343 - acc: 0.8507 - val_loss: 0.5641 - val_acc: 0.7421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "42b2420a-02ee-45ed-fb81-cd4077bfb4ab",
        "id": "wQsQGMefWTEA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEZCAYAAAB8culNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nORQcREQkh4KDiIjkUHAQEZEc/w8a7k5rFJ8TWAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEZCAYAAAB8culNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}